{"pageProps":{"post":{"title":"When It's Ok to Use Word Clouds","link":"https://vis4.net/blog/2015/01/when-its-ok-to-use-word-clouds/","pubDate":"2015-01-30T17:30:28.000Z","content":"<p><strong>tl;dr</strong> <em>It‚Äôs ok to use word clouds if your goal is to encourage reading of a large set of otherwise unrelated words that are connected to one or two interesting values (and word count in a text doesn‚Äôt qualify as interesting).</em></p><blockquote><p><a href=\"https://twitter.com/driven_by_data/status/560894208870195201\" target=\"_blank\" rel=\"noopener\">@driven_by_data</a>: In #datavis, no rule‚Äôs without exception. On rare occasions you can even use word clouds üòÉ</p></blockquote><p>This I <a href=\"https://twitter.com/driven_by_data/status/560894208870195201\" target=\"_blank\" rel=\"noopener\">tweeted yesterday</a> and now I feel that if I encourage the (dangerous) use of word clouds, I have to explain this exception in a little more detail. Why is it sometimes ok to use a widely rejected visualization method, and most times not?</p><p>A lot had been written about <a href=\"http://www.niemanlab.org/2011/10/word-clouds-considered-harmful/\" target=\"_blank\" rel=\"noopener\">why not to use</a> <a href=\"http://stephanieevergreen.com/word-cloud-dog-vomit/\" target=\"_blank\" rel=\"noopener\">word clouds</a>. It is super hard to decode or compare the values encoded in the font size or text color (if the latter isn‚Äôt random at all). Position, perhaps the most effective visual encoding, is essentially ‚Äòwasted‚Äô for the sake of a space filling algorithm (well, due to the spiraling nature of the layout algorithm, positions aren‚Äôt entirely random, but still, they don‚Äôt ‚Äúmean‚Äù anything in a word cloud).</p><p>Plus, thanks to <a href=\"http://wordle.net/\" target=\"_blank\" rel=\"noopener\">wordle.net</a>, a free-to-use online tool for creating word clouds, we probably all saw enough (bad) word clouds for a lifetime.</p><p>So why did I <a href=\"http://www.nytimes.com/interactive/2015/01/29/sunday-review/road-map-home-values-street-names.html\" target=\"_blank\" rel=\"noopener\">use a word cloud</a>?</p><p>The short answer is: because it was a good fit for the dataset. The data we got was pretty interesting. For each combination of street name and street suffix, <a href=\"http://zillow.com\" target=\"_blank\" rel=\"noopener\">Zillow</a> gave us the median home value according to their real estate database. Recently they used this data to <a href=\"http://www.nytimes.com/2015/01/25/opinion/sunday/the-secrets-of-street-names-and-home-values.html\" target=\"_blank\" rel=\"noopener\">write a story</a> on what a street name reveals about the home value. If you live on a <a href=\"http://www.nytimes.com/2015/01/25/opinion/sunday/the-secrets-of-street-names-and-home-values.html#street=Main&amp;suffix=St&amp;state=NY\" target=\"_blank\" rel=\"noopener\">Main Street</a>, your home is most likely less valuable than homes on Main Roads. Let‚Äôs put aside the problem of comparing individual homes with median homes across all streets with the same name (indeed, some readers complained that the data must be wrong, because in <em>their</em> city, Main St. clearly is the better place to live on etc.). It‚Äôs still an interesting dataset that you don‚Äôt see every day. So we wanted to do something more with it.</p><p>One of the first ideas that popped into my mind was Monopoly. Since we also got a per state and city breakdown of street name values, we could have made a ‚Äòcreate your own Monopoly‚Äô tool easily. Of course, plenty of localized Monopoly boards have been made already, but how many of them select streets based on actual home price value instead of some editorial judgement?</p><p><img src=\"/blog/images/old/ad3a81c55659f70db37c281b444c114d.png\" alt=\"Image by Fir0002/Flagstaffotos, CC BY-NC\"><span class=\"image-caption\">Image by Fir0002/Flagstaffotos, CC BY-NC</span></p><p>However, after checking back with our legal team at The Times, we had to dismiss this idea, which probably would not have been covered by the fair-use exception for use of copyrighted material.</p><p>So I was looking for something else to do with that data. I ran into some problems with simply showing a top x list of streets. Showing the most common streets was easy ‚Äì I forgot to mention that we also got the total number of homes per street name ‚Äì but showing the most valuable street names wasn‚Äôt. Unsurprisingly, the most valuable street names are in fact just some single streets on places like <a href=\"https://www.google.com/maps/place/Indian+Creek+Island+Rd,+Florida+33154/@25.8782246,-80.1323674,3a,75y,90t/data=!3m5!1e2!3m3!1s-v_Bk1EBVp9c%2FVDrzbFMaZNI%2FAAAAAAAAi7k%2F_SKyxFFl9Tc!2e4!3e15!4m2!3m1!1s0x88d9b291246d6ee9:0x80241346eaf539a3\" target=\"_blank\" rel=\"noopener\">Miami Beach golf course islands</a>. So that‚Äôs not really representative. Of course you can just filter out street names with less than X homes, or that appear in at fewer than Y states. But these cuts are arbitrary. The values I ‚Äúpick‚Äù for X and Y will directly change the make-up of the list of most valuable street names (because the top of the list will always include street names that barely make my filter criteria).</p><p>This kind of brought me to the idea of showing as many street names as possible. If top 20 list of most common street names is boring, maybe the top 1000 list isn‚Äôt. That‚Äôs where word clouds came into the game first. So mainly for looking at the most common streets I created this word cloud, in which street names are sized by the number of homes, and colored by the median home value (from the least valuable streets in gray to the most valuable ‚Äì among those 1000 streets ‚Äì in dark red):</p><p><img src=\"/blog/images/old/079894a0fbbd309bdf2e96aecdb65496.png\" alt=\"\"></p><p>And I immediately liked it. Limiting to two angles made it easier to read, and by shifting both angles a bit I reduced the readability disadvantage that the vertical text would have had otherwise. I felt that this form actually encourages to read through hundreds of street names, something that‚Äôs hard to achieve in any other form. Like, reading a thousand street names in an alphabetically ordered list is boring, ordering them by number of homes puts the more valuable streets at the bottom, making the list sortable makes it harder to visually memorize the location of streets, etc. The word cloud solves all these problems. But we weren‚Äôt quite there yet.</p><p>After all, by increasing the number of streets shown to a thousand I didn‚Äôt really solve my arbitrary filter problem. And by focussing on the most common streets I lose the interesting pattern of ‚Äòrich‚Äô street names.</p><p>That‚Äôs when I got back to Monopoly.</p><p>If we can‚Äôt use the Monopoly idea, perhaps I can find out what exactly I liked of it. Of course, the idea is without doubt the most fun view on street names, and with the game <a href=\"https://upload.wikimedia.org/wikipedia/commons/3/3c/BoardGamePatentMagie.png\" target=\"_blank\" rel=\"noopener\">being around for more than a century</a>, the view is also immediately familiar to a wide audience.</p><p>But what‚Äôs really great about Monopoly is the diversity of street names. The Monopoly board doesn‚Äôt just show the richest streets. It shows the most common (or at least recognizable) street names in eight different groups of street value (each with its own color). As if it wanted to include people from all levels of society, lower incomes, the middle class and the richest one percent.</p><p>At this point I had enough to make the word clouds work. By splitting the data up into sub-groups I was able to see the most common street names for different home values. Just like a Monopoly board, but with hundreds of streets in each cluster. The initially break-down into five equally sized groups (by of number of homes) was later I changed to a three group split, mainly because I felt the differences between the ‚Äòmiddle groups‚Äô wasn‚Äôt interesting enough to justify the extra panels. Then I wrote a few sentences to guide our readers through the graphic, and added the filters to help identifying interesting groups of street names in the mess of the cloud. And I also had some fun making the little icons üòÉ.</p><p>Click <a href=\"http://www.nytimes.com/interactive/2015/01/29/sunday-review/road-map-home-values-street-names.html\" target=\"_blank\" rel=\"noopener\">here to see the full graphic</a>.</p><div class=\"poster poster-945\"><p><img src=\"/blog/images/old/7f43cbd3b39a45e47f28cc5c9266d8f4.png\" alt=\"\"></p></div><p>Summing it up, I think that word clouds can work. But please don‚Äôt use them to make randomly colored word frequency charts. Just use <a href=\"http://www.nytimes.com/interactive/2012/09/06/us/politics/convention-word-counts.html?_r=1&amp;\" target=\"_blank\" rel=\"noopener\">word bubbles instead</a> (circle sizes are easier to compare, and you can use position to encode another value). Jim Vallandingham <a href=\"http://vallandingham.me/building_a_bubble_cloud.html\" target=\"_blank\" rel=\"noopener\">wrote a nice tutorial</a> that helps you getting started.</p><p><img src=\"/blog/images/old/c43a16eac827c1a01c4a8c4405880164.png\" alt=\"Source: The New York Times, 2012 (graphic by Mike Bostock, Shan Carter and Matthew Ericson)\"><span class=\"image-caption\">Source: The New York Times, 2012 (graphic by Mike Bostock, Shan Carter and Matthew Ericson)</span></p><p>Do you think I made a huge mistake by using word clouds? Have a different idea for this dataset that might have worked? Let me know!</p><p>Cheers!</p>","contentSnippet":"tl;dr It‚Äôs ok to use word clouds if your goal is to encourage reading of a large set of otherwise unrelated words that are connected to one or two interesting values (and word count in a text doesn‚Äôt qualify as interesting).\n\n@driven_by_data: In #datavis, no rule‚Äôs without exception. On rare occasions you can even use word clouds üòÉ\n\nThis I tweeted yesterday and now I feel that if I encourage the (dangerous) use of word clouds, I have to explain this exception in a little more detail. Why is it sometimes ok to use a widely rejected visualization method, and most times not?\nA lot had been written about why not to use word clouds. It is super hard to decode or compare the values encoded in the font size or text color (if the latter isn‚Äôt random at all). Position, perhaps the most effective visual encoding, is essentially ‚Äòwasted‚Äô for the sake of a space filling algorithm (well, due to the spiraling nature of the layout algorithm, positions aren‚Äôt entirely random, but still, they don‚Äôt ‚Äúmean‚Äù anything in a word cloud).\nPlus, thanks to wordle.net, a free-to-use online tool for creating word clouds, we probably all saw enough (bad) word clouds for a lifetime.\nSo why did I use a word cloud?\nThe short answer is: because it was a good fit for the dataset. The data we got was pretty interesting. For each combination of street name and street suffix, Zillow gave us the median home value according to their real estate database. Recently they used this data to write a story on what a street name reveals about the home value. If you live on a Main Street, your home is most likely less valuable than homes on Main Roads. Let‚Äôs put aside the problem of comparing individual homes with median homes across all streets with the same name (indeed, some readers complained that the data must be wrong, because in their city, Main St. clearly is the better place to live on etc.). It‚Äôs still an interesting dataset that you don‚Äôt see every day. So we wanted to do something more with it.\nOne of the first ideas that popped into my mind was Monopoly. Since we also got a per state and city breakdown of street name values, we could have made a ‚Äòcreate your own Monopoly‚Äô tool easily. Of course, plenty of localized Monopoly boards have been made already, but how many of them select streets based on actual home price value instead of some editorial judgement?\nImage by Fir0002/Flagstaffotos, CC BY-NC\nHowever, after checking back with our legal team at The Times, we had to dismiss this idea, which probably would not have been covered by the fair-use exception for use of copyrighted material.\nSo I was looking for something else to do with that data. I ran into some problems with simply showing a top x list of streets. Showing the most common streets was easy ‚Äì I forgot to mention that we also got the total number of homes per street name ‚Äì but showing the most valuable street names wasn‚Äôt. Unsurprisingly, the most valuable street names are in fact just some single streets on places like Miami Beach golf course islands. So that‚Äôs not really representative. Of course you can just filter out street names with less than X homes, or that appear in at fewer than Y states. But these cuts are arbitrary. The values I ‚Äúpick‚Äù for X and Y will directly change the make-up of the list of most valuable street names (because the top of the list will always include street names that barely make my filter criteria).\nThis kind of brought me to the idea of showing as many street names as possible. If top 20 list of most common street names is boring, maybe the top 1000 list isn‚Äôt. That‚Äôs where word clouds came into the game first. So mainly for looking at the most common streets I created this word cloud, in which street names are sized by the number of homes, and colored by the median home value (from the least valuable streets in gray to the most valuable ‚Äì among those 1000 streets ‚Äì in dark red):\n\nAnd I immediately liked it. Limiting to two angles made it easier to read, and by shifting both angles a bit I reduced the readability disadvantage that the vertical text would have had otherwise. I felt that this form actually encourages to read through hundreds of street names, something that‚Äôs hard to achieve in any other form. Like, reading a thousand street names in an alphabetically ordered list is boring, ordering them by number of homes puts the more valuable streets at the bottom, making the list sortable makes it harder to visually memorize the location of streets, etc. The word cloud solves all these problems. But we weren‚Äôt quite there yet.\nAfter all, by increasing the number of streets shown to a thousand I didn‚Äôt really solve my arbitrary filter problem. And by focussing on the most common streets I lose the interesting pattern of ‚Äòrich‚Äô street names.\nThat‚Äôs when I got back to Monopoly.\nIf we can‚Äôt use the Monopoly idea, perhaps I can find out what exactly I liked of it. Of course, the idea is without doubt the most fun view on street names, and with the game being around for more than a century, the view is also immediately familiar to a wide audience.\nBut what‚Äôs really great about Monopoly is the diversity of street names. The Monopoly board doesn‚Äôt just show the richest streets. It shows the most common (or at least recognizable) street names in eight different groups of street value (each with its own color). As if it wanted to include people from all levels of society, lower incomes, the middle class and the richest one percent.\nAt this point I had enough to make the word clouds work. By splitting the data up into sub-groups I was able to see the most common street names for different home values. Just like a Monopoly board, but with hundreds of streets in each cluster. The initially break-down into five equally sized groups (by of number of homes) was later I changed to a three group split, mainly because I felt the differences between the ‚Äòmiddle groups‚Äô wasn‚Äôt interesting enough to justify the extra panels. Then I wrote a few sentences to guide our readers through the graphic, and added the filters to help identifying interesting groups of street names in the mess of the cloud. And I also had some fun making the little icons üòÉ.\nClick here to see the full graphic.\n\n\n\nSumming it up, I think that word clouds can work. But please don‚Äôt use them to make randomly colored word frequency charts. Just use word bubbles instead (circle sizes are easier to compare, and you can use position to encode another value). Jim Vallandingham wrote a nice tutorial that helps you getting started.\nSource: The New York Times, 2012 (graphic by Mike Bostock, Shan Carter and Matthew Ericson)\nDo you think I made a huge mistake by using word clouds? Have a different idea for this dataset that might have worked? Let me know!\nCheers!","summary":"<p><strong>tl;dr</strong> <em>It‚Äôs ok to use word clouds if your goal is to encourage reading of a large set of otherwise unrelated words th","id":"https://vis4.net/blog/2015/01/when-its-ok-to-use-word-clouds/","isoDate":"2015-01-30T17:30:28.000Z","blogTitle":"vis4.net"}},"__N_SSG":true}