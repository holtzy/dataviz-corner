<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/dd8d3b5be9662933.css" as="style"/><link rel="stylesheet" href="/_next/static/css/dd8d3b5be9662933.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-59c5c889f52620d6.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-f11614d8aa7ee555.js" defer=""></script><script src="/_next/static/chunks/pages/_app-891652dd44e1e4e1.js" defer=""></script><script src="/_next/static/chunks/996-eeb5175dbd5dba8f.js" defer=""></script><script src="/_next/static/chunks/36-94b5e24e03efc6db.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...slug%5D-af748dcc13a25fcb.js" defer=""></script><script src="/_next/static/sFP8FhENNxqFJqEgxMEWp/_buildManifest.js" defer=""></script><script src="/_next/static/sFP8FhENNxqFJqEgxMEWp/_ssgManifest.js" defer=""></script></head><body><div id="__next"></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"creator":"Sherry Ricchiardi","title":"Data’s Role in the Disinformation War","link":"https://datajournalism.com/read/longreads/data-role-in-the-disinformation-war","pubDate":"Wed, 07 Sep 2022 08:00:00 +0200","author":"Sherry Ricchiardi","content":"\n                                                                        \u003cp\u003eA self-described “college nerd” sat on a porch in Birmingham, Ala., explaining via Zoom how he runs one of the most-followed Twitter feeds on the war in Ukraine.  Around \u003cstrong\u003e272,000\u003c/strong\u003e regularly check his account \u003cstrong\u003eThe Intel Crab\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eJustin Peden, 20, is an example of \u003cstrong\u003ehow data is being used to debunk disinformation\u003c/strong\u003e in today’s  high tech ecosystem.  He uses geolocation, satellite imagery, TikTok, Instagram and other sleuthing tools to monitor the deadliest conflict in Europe since World War II.\u003c/p\u003e\n\u003cp\u003eScouring the Internet for streaming Webcams, smartphone videos and still photos to pinpoint Russian troop locations, air bombardments and the destruction of once peaceful neighborhoods is a routine part of his day.  If a Russian commander denies bombing an area, Peden and other war watchers quickly post evidence exposing the falsehood.\u003c/p\u003e\n\u003cp\u003e“I never dreamed in a million years that what I was doing could end up being so relevant. I just wanted to expose people to what was going on [in Ukraine}.  I really am just a regular college kid,” said the University of Alabama – Birmingham junior. His Twitter profile photo is a crab holding a Ukrainian flag.\u003c/p\u003e\n\n                                                                     \n                            \n                                                                      \n                            \u003cp\u003e\u003cstrong\u003eOpen source intelligence has become a potent force\u003c/strong\u003e in a conflict the United Nations describes as “a grave humanitarian crisis.” Online detectives like Peden use data to break through the fog of war, operating on computers thousands of miles away. Their impact has not gone unnoticed.\u003c/p\u003e\n\u003cp\u003e“The intelligence gathering, fact-checking, and debunking is happening in real time. The online crowd is also documenting the movement and placement of Russian troops, creating something more than a snapshot of recent history. It is often actionable intelligence,” said veteran science journalist Miles O’Brien during a PBS – Public Broadcast Service --  program in April.\u003c/p\u003e\n\u003cp\u003eOn the air that day, O’Brien singled out Peden as “a highly regarded practitioner in the fast-growing field of open-source intelligence, or OSINT” and noted that his postings on Ukraine are followed “outside and inside the intelligence community.” The Washington Post included him in a story on the \u003cstrong\u003e“rise of Twitter spies.”\u003c/strong\u003e  \u003c/p\u003e\n\u003cp\u003eWhen the Russians invaded on Feb. 24, Peden combed through images on social media, using metadata embedded in still photos and video to pinpoint time and place they were taken. He learned a valuable lesson along the way.\u003c/p\u003e\n\u003cp\u003eAt one point, he received an image taken from a balcony in the southern port city of Kherson, showing what appeared to be Russian troops on the move. He verified the image and posted the exact coordinates on Twitter.\u003c/p\u003e\n\u003cp\u003eSuddenly, he realized \u003cstrong\u003ethe tweet might have placed a Ukrainian in danger\u003c/strong\u003e of being identified by the enemy. When he deleted the post minutes later, it had already been retweeted 100 times.  He no longer geolocates content in Russian occupied areas.\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003eTruth is first casualty\u003c/h3\u003e\n\u003cp\u003eWhat is happening now in Ukraine is nothing new. \u003cstrong\u003eDisinformation has been a factor in conflicts and dictatorships\u003c/strong\u003e dating back to the Roman Empire. Hitler and Stalin were masters at it.  There is the saying, “The first casualty of war is truth.”  \u003c/p\u003e\n\u003cp\u003eToday, however, there is a major shift in the equation.\u003c/p\u003e\n\u003cp\u003eWith the click of a mouse, anybody can transmit false information to the entire planet, no matter how dangerous, malicious or intimidating. \u003cstrong\u003eThe invasion of Ukraine is a textbook example of how digital untruths fueled a humanitarian crisis\u003c/strong\u003e and fomented hatred that has led to death and massive destruction.\u003c/p\u003e\n\u003cp\u003ePBSs O’Brien noted in a broadcast, “We are seeing a war unfold like never before.  What once might have been kept secret is out there for all of us to see. The real secret now? Knowing who to trust and what to believe.”  \u003c/p\u003e\n\u003cp\u003eO’Brien’s comment places journalists at the heart of the debate. Technology enables the spread of falsehoods. \u003cstrong\u003eOpen source intelligence helps set the record straight.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIt is important to note that \u003cstrong\u003edisinformation differs from misinformation\u003c/strong\u003e in that it not only is false but false as part of a “purposeful effort to mislead, deceive, or confuse.”  In short, it is content intended to harm.\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003eJournalists strike back\u003c/h3\u003e\n\u003cp\u003eHistorically, media have played a crucial role in debunking falsehoods about major events, from conspiracies about Covid vaccines, to climate change, immigration and, most recently, Russia’s invasion of Ukraine. \u003cstrong\u003eGermany’s Deutsche Welle (DW) is a prime example of how a verification system can expose actors with a malicious intent to inflict damage\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eIn the run-up to the war, DW’s fact-checking team began compiling a file of false claims and propaganda from both sides in the conflict and publishing corrections. They also made a startling discovery.  Fakes were being put out under their name.\u003c/p\u003e\n\u003cp\u003eIn July, they reported “Pro-Russian fabricated posts pretending to be those of the BBC, CNN and DW are fueling the mis- and disinformation war between Russia and Ukraine.” The story cited an example from a Japanese Twitter network.  Here is an excerpt: \u003c/p\u003e\n\u003cp\u003e \u003cstrong\u003e\"It looks like a DW report,\"\u003c/strong\u003e a Twitter user comments in Japanese on an alleged DW video about a Ukrainian refugee who is claimed to have raped women in Germany — serious accusations against a man named 'Petro Savchenko'. \u003c/p\u003e\n\u003cp\u003eThe Twitter user writes: `Please share with me the URL of the original video.’ The user seems to doubt the origin of the video — and rightly so. \u003ca href=\"https://www.dw.com/en/fact-check-fake-news-and-content-targets-international-media/a-62381229\"\u003e\u003cstrong\u003eIt is not a DW production\u003c/strong\u003e\u003c/a\u003e. It is a fake.”  \u003c/p\u003e\n\u003cp\u003eAmong other examples from the DW website: When a Twitter user posted a video purporting to be a live broadcast from Ukraine, a formation of fighter jets could be seen swooping over an urban area.  Using reverse image technology, \u003ca href=\"https://www.dw.com/en/fact-check-fake-news-thrives-amid-russia-ukraine-war/a-61477502\"\u003e\u003cstrong\u003efact checkers revealed it was from a 2020 air show near Moscow\u003c/strong\u003e\u003c/a\u003e.  Another video allegedly showing fierce air-to-ground combat between Russia and Ukraine was traced to a 2013 computer game.\u003c/p\u003e\n\u003cp\u003eDW turned to scholars and practitioners for suggestions on how to make fact-checking more effective. The advice is relevant to journalists anywhere in the world. Among the tips:\u003c/p\u003e\n\n                                                                      \n                            \n                                                                                                 \u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e“Emphasize correct information rather than amplifying claims”\u003c/strong\u003e (“Consider using truth sandwiches: first state what is true, then introduce the truthless or misleading statement and repeat the truth, so the falsehood is not the takeaway”\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e“Provide unambiguous assessments\u003c/strong\u003e (and avoid confusing labels like `mostly false’)”\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e“Avoid drawing false equivalencies between opposing viewpoints”\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e“Situate fact checks within broader issues\u003c/strong\u003e – don’t just focus on isolated claims“\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e“\u003ca href=\"https://www.dw.com/en/how-can-fact-checking-be-improved-some-suggestions-from-scholars-and-practitioners/a-55250869\"\u003eAnalyze and explain the strategies\u003c/a\u003e\u003c/strong\u003e behind misinformation – connect fact checks with media and information literacy”\u003c/li\u003e\n\u003c/ul\u003e\n\n                                                                     \n                            \u003cp\u003eThis list also prevents reporters from being duped into spreading false and misleading information. To the deceivers, any amplification of their message in mainstream media is the ultimate success. It gives their lies oxygen and authenticity. \u003c/p\u003e\n\u003cp\u003eThe \u003cstrong\u003e“Ghost of Kyiv,”\u003c/strong\u003e a false story about a heroic Ukrainian fighter pilot, made it into the Times of London, a home run for the fakers. Viral video showing the Ghost shooting down a Russian plane was viewed over 1.6 million times on Twitter. \u003ca href=\"https://www.wionews.com/world/ghost-of-kyiv-killed-in-fighting-after-shooting-down-40-russian-jets-475309\"\u003e\u003cstrong\u003eThe video  was from a video game simulator released in 2008\u003c/strong\u003e\u003c/a\u003e.\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003eRussia’s propaganda model\u003c/h3\u003e\n\u003cp\u003eGaining a better understanding of how propaganda techniques work to undermine truth is another way to disarm spin masters. A Rand corporation report on the “Russian Firehose of Falsehood” is a good place to start.\u003c/p\u003e\n\u003cp\u003eThe title refers to a strategy \u003cstrong\u003e“where a propagandist overwhelms the public by producing a never-ending stream of misinformation and falsehoods.”\u003c/strong\u003e  Even flagrant lies delivered rapidly and continuously, over multiple channels, such as news broadcasts and social media, can be effective in molding public opinion, according to the report.\u003c/p\u003e\n\u003cp\u003ePublished in 2016 at the height of the U.S. presidential election, this analysis provides a road map to how Russia’s disinformation system operates.  At the time, Russia was being accused of dirty tricks to influence American voters.\u003c/p\u003e\n\u003cp\u003e“The report is very much on target for what is going on today.  Bucket after bucket of nasty propaganda is being dumped on us,” said social scientist Christopher Paul, \u003ca href=\"https://www.rand.org/about/people/p/paul_christopher.html\"\u003e\u003cstrong\u003ethe report’s co-author\u003c/strong\u003e\u003c/a\u003e. His research includes counterterrorism, counterinsurgency and cyber warfare.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eThe report outlines and analyses four main components of the Russian model: \u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHigh volume and multi-channel\u003c/li\u003e\n\u003cli\u003eRapid, continuous, and repetitive\u003c/li\u003e\n\u003cli\u003eLacks commitment to objective reality\u003c/li\u003e\n\u003cli\u003eLacks commitment to consistency. \u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe Russians command a powerful arsenal of disinformation tools.  \u003c/p\u003e\n\u003cp\u003eBesides the usual, such as social media and satellite imagery, a vast network of internet trolls attack any views or information that runs counter to Vladimir Putin. They infiltrate online discussion forums, chat rooms and websites along with maintaining thousands of fake accounts on Twitter, Facebook and other platforms. \u003c/p\u003e\n\u003cp\u003eTheir mantra:  \u003cstrong\u003eRepetition works.\u003c/strong\u003e “Even with preposterous stories and urban legends, those who have heard them multiple times are more likely to believe that they are true,” said the report.  \u003c/p\u003e\n\u003cp\u003eThe Rand study offered best practices on how to beat the Russian Firehose of Falsehoods, among them, \u003cstrong\u003e“Don’t direct your flow of information directly back at the falsehood; \u003c/strong\u003einstead, point your stream at whatever the firehose is aimed at, and try to push that audience in more productive directions.” \u003c/p\u003e\n\u003cp\u003eOther tips included:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWarnings at the time of initial exposure to misinformation. \u003c/li\u003e\n\u003cli\u003eRepetition of the refutation or retraction,\u003c/li\u003e\n\u003cli\u003eCorrections that provide an alternative story to help fill the gap in understanding when false “facts” are removed.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e“It all goes back to journalistic standards.  All journalists really need to turn the screws is to be as professional as possible.  \u003cstrong\u003eDouble-checking, verifying sources, confirming attribution, using data to be accurate and reliable\u003c/strong\u003e. The burden of truth, the burden of evidence is much higher,” said Paul, a principal investigator for \u003ca href=\"https://www.rand.org/pubs/perspectives/PE198.html\"\u003e\u003cstrong\u003edefense and security-related research projects.\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eResearch by a disinformation team at the \u003cstrong\u003eStanford Internet Observatory (SIO\u003c/strong\u003e) supports that notion and provides fodder to data journalists. Led by scholar Shelby Grossman, they identify how to spot disinformation trends in the Russian- Ukraine war and defend against them.\u003c/p\u003e\n\u003cp\u003eFollowing is a sample of their findings:\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003e\u003cstrong\u003eThe trend: Old media circulating out of its original context\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eGrossman saw a video on her TikTok feed of a parachuter recording himself jumping out of a plane. It appeared he was a Russian soldier invading Ukraine.  In fact, the video was from 2015.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHow to spot\u003c/strong\u003e: If something seems suspicious or outrageous, \u003cstrong\u003euse reverse image searching to verify\u003c/strong\u003e. Upload a screenshot of the photo/video into the search bar of \u003cstrong\u003eGoogle Image\u003c/strong\u003e or \u003cstrong\u003eTinEye\u003c/strong\u003e to check where else it might have appeared.\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003e\u003cstrong\u003eThe trend: Hacked accounts\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eA Belarusian hacking group took over Ukrainian Facebook accounts and posted videos claiming to be of  Ukrainian soldiers surrendering.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHow to spot\u003c/strong\u003e: “Sometimes the name of the account is changed, but the handle – the username often denoted by the \u003cstrong\u003e@ symbol\u003c/strong\u003e – isn’t.  Advised Grossman: “Just spending 10 seconds looking at an account, in some cases one can realize that something is weird.”\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003e\u003cstrong\u003eThe trend: Pro-Kremlin narratives\u003c/strong\u003e\u003c/h3\u003e\n\u003cp\u003eBefore the invasion, claims began circulating that the West was fueling hysteria about impending attacks in order to boost President Biden politically. \u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHow to spot\u003c/strong\u003e: Look for \u003cstrong\u003ereports out of Russian state-affiliated media\u003c/strong\u003e. SIO reported that both Facebook and Twitter try to label these accounts, including some that are not commonly known to be connected to the Russian state. \u003c/p\u003e\n\u003cp\u003eGrossman would like to see platforms be more transparent and proactive.  “I think that would be useful and important.  It gives people information about the political agenda of the content and might give them pause before sharing”, she said in \u003ca href=\"https://news.stanford.edu/2022/03/03/seven-tips-spotting-disinformation-russia-ukraine-war/\"\u003e\u003cstrong\u003eSIO’s March report\u003c/strong\u003e\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eVeteran policy expert Kevin Sheives has another view. He believes civil society, not government and social media companies, is better suited to fight back against disinformation.\u003c/p\u003e\n\u003cp\u003e“We are looking for solutions in the wrong place. The campaign against disinformation should have civil society at its core,” said Sheives, associate director, International Forum for Democratic Studies, National Endowment for Democracy. \u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.ned.org/wp-content/uploads/2021/12/Toward-A-Globally-Networked-Counter-Disinformation-Response-Kevin-Sheives.pdf\"\u003e\u003cstrong\u003eHe points out that social media platforms and governments are not designed to prioritize values over business or national interests\u003c/strong\u003e\u003c/a\u003e. That leaves it to journalists, fact-checkers, community groups, and advocates to create counter-disinformation networks.\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003eCountering disinformation networks\u003c/h3\u003e\n\u003cp\u003e  “TikTok algorithm directs users to fake news about Ukraine war, study says.”  This headline appeared in The Guardian, March 21, 2022.  \u003c/p\u003e\n\u003cp\u003eAn investigation, conducted by \u003ca href=\"https://www.newsguardtech.com/\"\u003e\u003cstrong\u003eNewsGuard\u003c/strong\u003e\u003c/a\u003e, a website that monitors online disinformation, discovered that a new TikTok account “can be shown falsehoods about the Ukraine war within minutes of signing up to the app.” \u003c/p\u003e\n\u003cp\u003eAmong NewsGuard’s findings, “At a time when false narratives about the Russia-Ukraine conflict are proliferating online, none of the videos fed to our analysts by TikTok’s algorithm contained any information about the trustworthiness of the source, warnings, fact-checks, or additional information that could empower users with reliable information.” \u003c/p\u003e\n\u003cp\u003eHow NewsGuard did it: Researchers created new accounts on the app and spent 45 minutes scrolling through the For You Page, stopping to view in full any video that looked like it was about the war in Ukraine, according to the report.  \u003c/p\u003e\n\u003cp\u003eAround the same time, \u003ca href=\"https://www.theguardian.com/technology/2022/mar/21/tiktok-algorithm-directs-users-to-fake-news-about-ukraine-war-study-says\"\u003e\u003cstrong\u003ethe BBC listed several categories of misleading content\u003c/strong\u003e\u003c/a\u003e about the war appearing on TikTok, describing it as “one of the leading platforms for snappy false videos about the war in Ukraine which are reaching millions.” \u003c/p\u003e\n\u003cp\u003eA TikTok spokesperson noted the company has added more resources to fact-check Russian and Ukrainian content, including local language experts, and beefed up safety and security resources \u003ca href=\"https://www.bbc.com/news/60867414\"\u003e\u003cstrong\u003e“to detect emerging threats and remove harmful misinformation.”\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSince the invasion, many social media platforms and messaging services have taken steps to block state-sponsored or state-affiliated media or add labels to alert users to the source of the information.  The jury is out on how well these efforts will work to improve transparency and credibility of information.\u003c/p\u003e\n\u003cp\u003eThe stakes are high. Misinformation and disinformation can have life or death consequences and undermine the democratic way of life. Data journalists are in the thick of this expanding field of digital warfare. Are they up to the challenge as more sophisticated methods of deception sweep the globe?\u003c/p\u003e\n\n                                                                                                 \u003ch3\u003e\u003cstrong\u003eResources that can help\u003c/strong\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://s3.eu-central-1.amazonaws.com/datajournalismcom/handbooks/The-Data-Journalism-Handbook-2.pdf\"\u003e\u003cstrong\u003eEuropean Journalism Center/Google News Initiative: “The Data Journalism Handbook 2,”\u003c/strong\u003e\u003c/a\u003e a wide range of topics, including data visualization, digital forensics and open source coding practices.  The long content list provides a smorgasbord of choices. \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://s3.eu-central-1.amazonaws.com/datajournalismcom/handbooks/Verification-Handbook-3.pdf\"\u003e\u003cstrong\u003e European Journalism Center: “Verification Handbook: For Disinformation and Media Manipulation,” \u003c/strong\u003e\u003c/a\u003eincludes sections on investigating social media, verifying images, and spotting bots, cyborgs, an inauthentic activity.  Supported by the Craig Newmark Philanthropies. \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://counteringdisinformation.org/\"\u003e\u003cstrong\u003eUnited States Agency for International Development (USAID\u003c/strong\u003e)\u003c/a\u003e: According to the website, this is the first-ever global database of organizations and initiatives working on to counter disinformation that includes more than 270 entries from more than 80 countries. Worth a review to see how your region of interest fares. \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://en.unesco.org/sites/default/files/journalism_fake_news_disinformation_print_friendly_0.pdf\"\u003e\u003cstrong\u003eUNESCO:  “Handbook on Journalism, `Fake News,” and Disinformation.”\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eDeutsche Welle: \u003ca href=\"https://www.dw.com/en/fact-checking-a-curated-guide-to-resources-and-ideas/a-54509776\"\u003e\u003cstrong\u003e“Fact-check: The deepfakes in the disinformation war between Russia and Ukraine,”\u003c/strong\u003e\u003c/a\u003e a curated guide to resources and ideas.  \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://ksj.mit.edu/resource/data-journalism-tools/toolkits-and-programs/\"\u003e\u003cstrong\u003e Knight Science Journalism Program, MIT: Data Journalism Toolkit,” \u003c/strong\u003e\u003c/a\u003e offers a diverse collection of tools to help journalists analyze, visualize, map and otherwise make use of data.  Includes “10 Tools for Data Journalist Tool Belt,” compiled by an Associated Press editor. \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.journaliststoolbox.org/2022/07/23/data-tools-tipsheets-and-research/\"\u003e\u003cstrong\u003eSociety of Professional Journalists: “Data tools and tip sheets.\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n                                             \n                ","contentSnippet":"A self-described “college nerd” sat on a porch in Birmingham, Ala., explaining via Zoom how he runs one of the most-followed Twitter feeds on the war in Ukraine.  Around 272,000 regularly check his account The Intel Crab.\nJustin Peden, 20, is an example of how data is being used to debunk disinformation in today’s  high tech ecosystem.  He uses geolocation, satellite imagery, TikTok, Instagram and other sleuthing tools to monitor the deadliest conflict in Europe since World War II.\nScouring the Internet for streaming Webcams, smartphone videos and still photos to pinpoint Russian troop locations, air bombardments and the destruction of once peaceful neighborhoods is a routine part of his day.  If a Russian commander denies bombing an area, Peden and other war watchers quickly post evidence exposing the falsehood.\n“I never dreamed in a million years that what I was doing could end up being so relevant. I just wanted to expose people to what was going on [in Ukraine}.  I really am just a regular college kid,” said the University of Alabama – Birmingham junior. His Twitter profile photo is a crab holding a Ukrainian flag.\nOpen source intelligence has become a potent force in a conflict the United Nations describes as “a grave humanitarian crisis.” Online detectives like Peden use data to break through the fog of war, operating on computers thousands of miles away. Their impact has not gone unnoticed.\n“The intelligence gathering, fact-checking, and debunking is happening in real time. The online crowd is also documenting the movement and placement of Russian troops, creating something more than a snapshot of recent history. It is often actionable intelligence,” said veteran science journalist Miles O’Brien during a PBS – Public Broadcast Service --  program in April.\nOn the air that day, O’Brien singled out Peden as “a highly regarded practitioner in the fast-growing field of open-source intelligence, or OSINT” and noted that his postings on Ukraine are followed “outside and inside the intelligence community.” The Washington Post included him in a story on the “rise of Twitter spies.”  \nWhen the Russians invaded on Feb. 24, Peden combed through images on social media, using metadata embedded in still photos and video to pinpoint time and place they were taken. He learned a valuable lesson along the way.\nAt one point, he received an image taken from a balcony in the southern port city of Kherson, showing what appeared to be Russian troops on the move. He verified the image and posted the exact coordinates on Twitter.\nSuddenly, he realized the tweet might have placed a Ukrainian in danger of being identified by the enemy. When he deleted the post minutes later, it had already been retweeted 100 times.  He no longer geolocates content in Russian occupied areas.\nTruth is first casualty\nWhat is happening now in Ukraine is nothing new. Disinformation has been a factor in conflicts and dictatorships dating back to the Roman Empire. Hitler and Stalin were masters at it.  There is the saying, “The first casualty of war is truth.”  \nToday, however, there is a major shift in the equation.\nWith the click of a mouse, anybody can transmit false information to the entire planet, no matter how dangerous, malicious or intimidating. The invasion of Ukraine is a textbook example of how digital untruths fueled a humanitarian crisis and fomented hatred that has led to death and massive destruction.\nPBSs O’Brien noted in a broadcast, “We are seeing a war unfold like never before.  What once might have been kept secret is out there for all of us to see. The real secret now? Knowing who to trust and what to believe.”  \nO’Brien’s comment places journalists at the heart of the debate. Technology enables the spread of falsehoods. Open source intelligence helps set the record straight.\nIt is important to note that disinformation differs from misinformation in that it not only is false but false as part of a “purposeful effort to mislead, deceive, or confuse.”  In short, it is content intended to harm.\nJournalists strike back\nHistorically, media have played a crucial role in debunking falsehoods about major events, from conspiracies about Covid vaccines, to climate change, immigration and, most recently, Russia’s invasion of Ukraine. Germany’s Deutsche Welle (DW) is a prime example of how a verification system can expose actors with a malicious intent to inflict damage.\nIn the run-up to the war, DW’s fact-checking team began compiling a file of false claims and propaganda from both sides in the conflict and publishing corrections. They also made a startling discovery.  Fakes were being put out under their name.\nIn July, they reported “Pro-Russian fabricated posts pretending to be those of the BBC, CNN and DW are fueling the mis- and disinformation war between Russia and Ukraine.” The story cited an example from a Japanese Twitter network.  Here is an excerpt: \n \"It looks like a DW report,\" a Twitter user comments in Japanese on an alleged DW video about a Ukrainian refugee who is claimed to have raped women in Germany — serious accusations against a man named 'Petro Savchenko'. \nThe Twitter user writes: `Please share with me the URL of the original video.’ The user seems to doubt the origin of the video — and rightly so. It is not a DW production. It is a fake.”  \nAmong other examples from the DW website: When a Twitter user posted a video purporting to be a live broadcast from Ukraine, a formation of fighter jets could be seen swooping over an urban area.  Using reverse image technology, fact checkers revealed it was from a 2020 air show near Moscow.  Another video allegedly showing fierce air-to-ground combat between Russia and Ukraine was traced to a 2013 computer game.\nDW turned to scholars and practitioners for suggestions on how to make fact-checking more effective. The advice is relevant to journalists anywhere in the world. Among the tips:\n“Emphasize correct information rather than amplifying claims” (“Consider using truth sandwiches: first state what is true, then introduce the truthless or misleading statement and repeat the truth, so the falsehood is not the takeaway”\n“Provide unambiguous assessments (and avoid confusing labels like `mostly false’)”\n“Avoid drawing false equivalencies between opposing viewpoints”\n“Situate fact checks within broader issues – don’t just focus on isolated claims“\n“Analyze and explain the strategies behind misinformation – connect fact checks with media and information literacy”\nThis list also prevents reporters from being duped into spreading false and misleading information. To the deceivers, any amplification of their message in mainstream media is the ultimate success. It gives their lies oxygen and authenticity. \nThe “Ghost of Kyiv,” a false story about a heroic Ukrainian fighter pilot, made it into the Times of London, a home run for the fakers. Viral video showing the Ghost shooting down a Russian plane was viewed over 1.6 million times on Twitter. The video  was from a video game simulator released in 2008.\nRussia’s propaganda model\nGaining a better understanding of how propaganda techniques work to undermine truth is another way to disarm spin masters. A Rand corporation report on the “Russian Firehose of Falsehood” is a good place to start.\nThe title refers to a strategy “where a propagandist overwhelms the public by producing a never-ending stream of misinformation and falsehoods.”  Even flagrant lies delivered rapidly and continuously, over multiple channels, such as news broadcasts and social media, can be effective in molding public opinion, according to the report.\nPublished in 2016 at the height of the U.S. presidential election, this analysis provides a road map to how Russia’s disinformation system operates.  At the time, Russia was being accused of dirty tricks to influence American voters.\n“The report is very much on target for what is going on today.  Bucket after bucket of nasty propaganda is being dumped on us,” said social scientist Christopher Paul, the report’s co-author. His research includes counterterrorism, counterinsurgency and cyber warfare.\nThe report outlines and analyses four main components of the Russian model: \nHigh volume and multi-channel\nRapid, continuous, and repetitive\nLacks commitment to objective reality\nLacks commitment to consistency. \nThe Russians command a powerful arsenal of disinformation tools.  \nBesides the usual, such as social media and satellite imagery, a vast network of internet trolls attack any views or information that runs counter to Vladimir Putin. They infiltrate online discussion forums, chat rooms and websites along with maintaining thousands of fake accounts on Twitter, Facebook and other platforms. \nTheir mantra:  Repetition works. “Even with preposterous stories and urban legends, those who have heard them multiple times are more likely to believe that they are true,” said the report.  \nThe Rand study offered best practices on how to beat the Russian Firehose of Falsehoods, among them, “Don’t direct your flow of information directly back at the falsehood; instead, point your stream at whatever the firehose is aimed at, and try to push that audience in more productive directions.” \nOther tips included:\nWarnings at the time of initial exposure to misinformation. \nRepetition of the refutation or retraction,\nCorrections that provide an alternative story to help fill the gap in understanding when false “facts” are removed.\n“It all goes back to journalistic standards.  All journalists really need to turn the screws is to be as professional as possible.  Double-checking, verifying sources, confirming attribution, using data to be accurate and reliable. The burden of truth, the burden of evidence is much higher,” said Paul, a principal investigator for defense and security-related research projects.\nResearch by a disinformation team at the Stanford Internet Observatory (SIO) supports that notion and provides fodder to data journalists. Led by scholar Shelby Grossman, they identify how to spot disinformation trends in the Russian- Ukraine war and defend against them.\nFollowing is a sample of their findings:\nThe trend: Old media circulating out of its original context\nGrossman saw a video on her TikTok feed of a parachuter recording himself jumping out of a plane. It appeared he was a Russian soldier invading Ukraine.  In fact, the video was from 2015.\nHow to spot: If something seems suspicious or outrageous, use reverse image searching to verify. Upload a screenshot of the photo/video into the search bar of Google Image or TinEye to check where else it might have appeared.\nThe trend: Hacked accounts\nA Belarusian hacking group took over Ukrainian Facebook accounts and posted videos claiming to be of  Ukrainian soldiers surrendering.\nHow to spot: “Sometimes the name of the account is changed, but the handle – the username often denoted by the @ symbol – isn’t.  Advised Grossman: “Just spending 10 seconds looking at an account, in some cases one can realize that something is weird.”\nThe trend: Pro-Kremlin narratives\nBefore the invasion, claims began circulating that the West was fueling hysteria about impending attacks in order to boost President Biden politically. \nHow to spot: Look for reports out of Russian state-affiliated media. SIO reported that both Facebook and Twitter try to label these accounts, including some that are not commonly known to be connected to the Russian state. \nGrossman would like to see platforms be more transparent and proactive.  “I think that would be useful and important.  It gives people information about the political agenda of the content and might give them pause before sharing”, she said in SIO’s March report.\nVeteran policy expert Kevin Sheives has another view. He believes civil society, not government and social media companies, is better suited to fight back against disinformation.\n“We are looking for solutions in the wrong place. The campaign against disinformation should have civil society at its core,” said Sheives, associate director, International Forum for Democratic Studies, National Endowment for Democracy. \nHe points out that social media platforms and governments are not designed to prioritize values over business or national interests. That leaves it to journalists, fact-checkers, community groups, and advocates to create counter-disinformation networks.\nCountering disinformation networks\n  “TikTok algorithm directs users to fake news about Ukraine war, study says.”  This headline appeared in The Guardian, March 21, 2022.  \nAn investigation, conducted by NewsGuard, a website that monitors online disinformation, discovered that a new TikTok account “can be shown falsehoods about the Ukraine war within minutes of signing up to the app.” \nAmong NewsGuard’s findings, “At a time when false narratives about the Russia-Ukraine conflict are proliferating online, none of the videos fed to our analysts by TikTok’s algorithm contained any information about the trustworthiness of the source, warnings, fact-checks, or additional information that could empower users with reliable information.” \nHow NewsGuard did it: Researchers created new accounts on the app and spent 45 minutes scrolling through the For You Page, stopping to view in full any video that looked like it was about the war in Ukraine, according to the report.  \nAround the same time, the BBC listed several categories of misleading content about the war appearing on TikTok, describing it as “one of the leading platforms for snappy false videos about the war in Ukraine which are reaching millions.” \nA TikTok spokesperson noted the company has added more resources to fact-check Russian and Ukrainian content, including local language experts, and beefed up safety and security resources “to detect emerging threats and remove harmful misinformation.”\nSince the invasion, many social media platforms and messaging services have taken steps to block state-sponsored or state-affiliated media or add labels to alert users to the source of the information.  The jury is out on how well these efforts will work to improve transparency and credibility of information.\nThe stakes are high. Misinformation and disinformation can have life or death consequences and undermine the democratic way of life. Data journalists are in the thick of this expanding field of digital warfare. Are they up to the challenge as more sophisticated methods of deception sweep the globe?\nResources that can help\nEuropean Journalism Center/Google News Initiative: “The Data Journalism Handbook 2,” a wide range of topics, including data visualization, digital forensics and open source coding practices.  The long content list provides a smorgasbord of choices. \n European Journalism Center: “Verification Handbook: For Disinformation and Media Manipulation,” includes sections on investigating social media, verifying images, and spotting bots, cyborgs, an inauthentic activity.  Supported by the Craig Newmark Philanthropies. \nUnited States Agency for International Development (USAID): According to the website, this is the first-ever global database of organizations and initiatives working on to counter disinformation that includes more than 270 entries from more than 80 countries. Worth a review to see how your region of interest fares. \nUNESCO:  “Handbook on Journalism, `Fake News,” and Disinformation.”\nDeutsche Welle: “Fact-check: The deepfakes in the disinformation war between Russia and Ukraine,” a curated guide to resources and ideas.  \n Knight Science Journalism Program, MIT: Data Journalism Toolkit,”  offers a diverse collection of tools to help journalists analyze, visualize, map and otherwise make use of data.  Includes “10 Tools for Data Journalist Tool Belt,” compiled by an Associated Press editor. \nSociety of Professional Journalists: “Data tools and tip sheets.","guid":"https://datajournalism.com/read/longreads/data-role-in-the-disinformation-war","isoDate":"2022-09-07T06:00:00.000Z","blogTitle":"DataJournalism.com"}},"__N_SSG":true},"page":"/[...slug]","query":{"slug":["datas-role-in-the-disinformation-war"]},"buildId":"sFP8FhENNxqFJqEgxMEWp","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>