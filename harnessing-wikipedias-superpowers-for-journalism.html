<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/dd8d3b5be9662933.css" as="style"/><link rel="stylesheet" href="/_next/static/css/dd8d3b5be9662933.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-59c5c889f52620d6.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-f11614d8aa7ee555.js" defer=""></script><script src="/_next/static/chunks/pages/_app-694ee0f2821639fc.js" defer=""></script><script src="/_next/static/chunks/996-eeb5175dbd5dba8f.js" defer=""></script><script src="/_next/static/chunks/36-94b5e24e03efc6db.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...slug%5D-af748dcc13a25fcb.js" defer=""></script><script src="/_next/static/0XYe7aucOTe3b0iK50JEi/_buildManifest.js" defer=""></script><script src="/_next/static/0XYe7aucOTe3b0iK50JEi/_ssgManifest.js" defer=""></script></head><body><div id="__next"></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"creator":"Monika Sengul-Jones","title":"Harnessing Wikipedia's superpowers for journalism","link":"https://datajournalism.com/read/longreads/harnessing-wikipedias-superpowers-for-journalism","pubDate":"Wed, 02 Dec 2020 07:00:00 +0100","author":"Monika Sengul-Jones","content":"\n                                                                                                                    \u003cp\u003eOrientations to Wikipedia often begin with its enormity. And it is enormous. The encyclopedia will be 20 years old in January 2021 and has more than 53 million articles in \u003ca href=\"https://meta.wikimedia.org/wiki/List_of_Wikipedias\"\u003e314 languages\u003c/a\u003e. \u003ca href=\"https://en.wikipedia.org/wiki/Special:Statistics\"\u003eSix million are in English\u003c/a\u003e. According to Alexa.com, \u003ca href=\"https://www.alexa.com/topsites/countries/US\"\u003eWikipedia is the 8th most-visited web domain in the United States\u003c/a\u003e, and the \u003ca href=\"https://www.alexa.com/topsites\"\u003e13th globally\u003c/a\u003e; it’s the only non-profit in the top-100 domains. In November 2020, more than 1.7 billion unique devices from around the world accessed Wikipedia articles. Average monthly pageviews surpass 20 billion. \u003c/p\u003e\n\u003cp\u003eBeyond reach, there’s the data. All data on and about all Wikipedias—from pageview statistics, \u003ca href=\"https://diff.wikimedia.org/2018/04/05/ten-most-cited-sources-wikipedia/\"\u003emost-frequently cited references\u003c/a\u003e, to access to every version ever written and all the editors who have ever contributed to it—is \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Copyrights\"\u003efreely available\u003c/a\u003e. Entire version histories are available at \u003ca href=\"https://dumps.wikimedia.org/\"\u003edumps.wikimedia.org\u003c/a\u003e.\u003c/p\u003e\n\n                                                                     \n                            \u003cp\u003eTwitter bots that share edited Wikipedia entries text from high impact IP addresses, such as the White House, which is covered by the @whitehouseedits bot, pictured above, can help data journalists track malfeasance. But there’s evidence the bots can be manipulated. Image credit: \u003ca href=\"https://twitter.com/whitehousedits/status/1293889545805672451/photo/1\"\u003eTwitter @Whitehousedits\u003c/a\u003e\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eThanks to the free and open access to billions of human and machine-readable data, corporations and research centres have been leveraging Wikipedia for research for years. \u003ca href=\"https://com.uw.edu/people/faculty/benjamin-mako-hill/\"\u003eBenjamin Mako Hill\u003c/a\u003e, assistant professor of communication at the \u003ca href=\"https://www.washington.edu/\"\u003eUniversity of Washington\u003c/a\u003e and \u003ca href=\"https://communication.northwestern.edu/faculty/aaron-shaw\"\u003eAaron Shaw\u003c/a\u003e, associate professor of communication at \u003ca href=\"https://www.northwestern.edu/\"\u003eNorthwestern University\u003c/a\u003e, describe Wikipedia as the “most important laboratory for social scientific and computing research in history” in \u003ca href=\"https://wikipedia20.pubpub.org/pub/fgas2h4l/release/2\"\u003etheir chapter\u003c/a\u003e in \u003ca href=\"https://wikipedia20.pubpub.org/\"\u003e\"Wikipedia@20\"\u003c/a\u003e, a new book on Wikipedia published by MIT Press, edited by Joseph Reagle and Jackie Koerner. \u003c/p\u003e\n\u003cp\u003e“Wikipedia has become part of the mainstream of every social and computational research field we know of,” Hill and Shaw write. Google’s knowledge graph and smart AI technologies, such as Amazon’s Alexa and Google Home, are based on metadata from \u003ca href=\"https://meta.wikimedia.org/wiki/Wikimedia_projects\"\u003eWikimedia projects\u003c/a\u003e, of which Wikipedia is the best-known. Significant for data journalists is how Wikipedia’s influence has already surpassed clicks to article pages; in a way, the internet is already Wikipedia’s world, we’re just living in it.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eBut journalists know well that ubiquity shouldn’t stand in for universality. We should be mindful that indiscriminate use of “big data” without acknowledging context reproduces what \u003ca href=\"https://www.media.mit.edu/people/joyab/overview/\"\u003eJoy Buolamwini\u003c/a\u003e, founder of the \u003ca href=\"https://www.ajl.org/\"\u003eAlgorithmic Justice League\u003c/a\u003e, calls the \u003ca href=\"https://www.youtube.com/watch?v=ZSJXKoD6mA8\"\u003e“coded gaze” of white data\u003c/a\u003e. \u003ca href=\"https://safiyaunoble.com/\"\u003eSafiya Umoja Noble\u003c/a\u003e, a critical information studies expert and associate professor at \u003ca href=\"https://is.gseis.ucla.edu/\"\u003eUCLA\u003c/a\u003e, challenges the acceptance of invisible values that normalise algorithmic hierarchies. \u003c/p\u003e\n\u003cp\u003eInternet search results, which often prioritise Wikipedia articles in addition to using Wikipedia’s infobox data or structured data in sidebars, “feign impartiality and objectivity in the process of displaying results” Noble writes in \u003ca href=\"http://algorithmsofoppression.com/\"\u003e\"Algorithms of Oppression: How Search Engines Reinforce Racism\"\u003c/a\u003e. \u003c/p\u003e\n\u003cp\u003eSystemic biases on Wikipedia, including \u003ca href=\"https://meta.wikimedia.org/wiki/Research:Knowledge_Gaps_Index/Taxonomy/Full_paper#Sociodemographics_Gaps\"\u003ewell-documented “gaps” in coverage, readership, and source\u003c/a\u003e, are cause for pause. Globally, volunteer contributors are predominately white males from the northern hemisphere. On English Wikipedia, less than 20% of editors self-identify as female. Asymmetries in participation have impacted the editorial processes and content. Editors who \u003ca href=\"https://upload.wikimedia.org/wikipedia/commons/7/77/The_Heart_Work_of_Wikipedia_Gendered,_Emotional_Labor_in_the_World%27s_Largest_Online_Encyclopedia.pdf\"\u003eself-identify as women often perform “emotional work”\u003c/a\u003e to justify their contributions. Women and nonbinary users on Wikipedia may encounter \u003ca href=\"https://meta.wikimedia.org/wiki/Research:Communicating_on_Wikipedia_while_female\"\u003ehostile, violent language\u003c/a\u003e and some have experienced harassment and doxing. Then there are the asymmetries in the breadth and depth of coverage; only approximately 17% of biographies on English Wikipedia are about women.\u003c/p\u003e\n\n                                                                                                 \u003cp\u003e\u003cstrong\u003e How to contribute to Wikipedia\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eAnyone can edit Wikipedia, but there is an editorial pecking order and policies to keep in mind. Tips for success:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003eAssuming you have \u003ca href=\"https://en.wikipedia.org/w/index.php?title=Special:CreateAccount\u0026amp;returnto=Wikipedia:Why_create_an_account%3F\"\u003ecreated an account\u003c/a\u003e, be sure to include a bio on your \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:User_pages\"\u003euser page\u003c/a\u003e (you don't need to use your real name, but you can).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eImprove existing articles to begin, you can create new articles once your account is four days old and you’ve made ten edits.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eInclude \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Verifiability\"\u003everifiable citations\u003c/a\u003e to secondary sources for any new claims--or claims where a citation is needed.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eBe aware of Wikipedia’s guidelines on \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Conflict_of_interest\"\u003econflicts of interest\u003c/a\u003e.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBeyond this, there are many tutorials and videos with various tips and tricks. Among them, \u003ca href=\"https://www.groovypost.com/howto/guide-getting-started-wikipedia-contributor/#:~:text=Creating%20Your%20Registered%20Wikipedia%20Account\u0026amp;text=Select%20%E2%80%9Chelp%20me%20choose%E2%80%9D%20if,and%20now%20a%20Wikipedia%20contributor\"\u003ethis is a useful high-level summary\u003c/a\u003e, while an \u003ca href=\"https://outreachdashboard.wmflabs.org/training/editing-wikipedia/editing-basics\"\u003eediting tutorial\u003c/a\u003e hosted by the Wikimedia Foundation walks you through nitty-gritty basics.\u003c/p\u003e\n\n                                                                     \n                            \u003cp\u003eWith this glut of imperfect or missing data, what’s a data journalist to do? Journalists doing internet research might consider that they are already knee-deep in a minefield of constraints. \u003c/p\u003e\n\u003cp\u003e“The reality for journalists working on the internet is fraught,” said Hill. “Most internet data sets are controlled by commercial companies. That means there’s never going to be a full data set and what’s available has been—or is being—manipulated. Wikipedia is different. It’s free, it’s accessible, and it’s from a public service organisation.” Like any institution, as \u003ca href=\"https://dusp.mit.edu/faculty/catherine-dignazio\"\u003eCatherine D’Ignazio\u003c/a\u003e has pointed out \u003ca href=\"https://datajournalism.com/read/longreads/putting-data-back-into-context\"\u003ein this publication\u003c/a\u003e, context may be hard to find. On Wikipedia, that’s often due to the decentralised organisation of open source projects; volunteers come and go, rather than intentional obfuscation.  \u003c/p\u003e\n\u003cp\u003eNevertheless, \u003ca href=\"https://www.wired.com/author/noam-cohen/\"\u003eNoam Cohen\u003c/a\u003e, a journalist for Wired and The New York Times who has written about Wikipedia for nearly two decades, said in a phone interview that journalists should—if they are not already—use Wikipedia’s data, including pageviews and the layers of information found in article pages. But Cohen cautions journalists not to let Wikipedia’s decisions on coverage replace news judgement. “In journalism, word length is often a sign of importance,” Cohen said. “That’s not the case on Wikipedia, there are articles about \"The Simpsons\" or characters on \"Lost\" that are longer than articles about important women scientists or philosophers. But these trends don’t mean there are not rules. There are, the information is changing.”\u003c/p\u003e\n\n                                                                                                 \u003cblockquote\u003e\u003cp\u003eTo leverage Wikipedia’s superpowers for data journalism, it’s best to climb into the belly of the beast.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003cp\u003eLast year, Cohen’s editor asked him to write about why his Wikipedia biography—which he did not create, there are guidelines barring \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Conflict_of_interest\"\u003e“conflict of interest editing”\u003c/a\u003e—was deleted. Cohen dug in and \u003ca href=\"https://www.wired.com/story/socked-into-the-puppet-hole-on-wikipedia/\"\u003ediscovered it was due to “sock-puppetry;\u003c/a\u003e” that’s shorthand for editors who use more than one account without disclosure. Later, another editor restored Cohen’s biography. \u003c/p\u003e\n\u003cp\u003eStories like this may give journalists discomfort about the contingencies of the online encyclopedia, and any data sets therein. And for as long as there’s been Wikipedia, there have been editors and professors warning us to stay away. But Cohen suggests thinking otherwise. “The fact that information is slowly being changed and is always saved is Wikipedia’s superpower,” said Cohen. To leverage Wikipedia’s superpowers for data journalism, it’s best to climb into the belly of the beast.\u003c/p\u003e\n\n                                                                      \n                            \u003ch2\u003eUnderstand how Wikipedia’s authority works\u003c/h2\u003e\n\u003cp\u003eWhile one might reasonably guess that \u003ca href=\"https://wikimediafoundation.org/\"\u003eThe Wikipedia Foundation\u003c/a\u003e manages editorial oversight, that’s not the case. All content decisions, including developing and managing bots to do tedious, repetitive tasks—fixing redirects or reverting vandalism, as \u003ca href=\"https://en.wikipedia.org/wiki/User:ClueBot_NG\"\u003eClueBot_NG\u003c/a\u003e does—are designed and run by volunteers. The Wikipedia community has developed a number of policies and guidelines to govern editing, including a rule about verifiability and a blacklist of publications not allowed to be cited on Wikipedia. Blacklisted publications include spam and publications that do not fact check and circulate conspiracy theories.\u003c/p\u003e\n\u003cp\u003eIn 2017, Katherine Maher, executive director of The Wikimedia Foundation, \u003ca href=\"https://www.theguardian.com/technology/2017/feb/12/wikipedia-daily-mail-reliability-ban-katherine-maher\"\u003espoke with The Guardian\u003c/a\u003e about the volunteer community’s decision to blacklist The Daily Mail as a reliable source. “It’s amazing [Wikipedia] works in practice,” she said, motioning to a concept that academics have called peer-production or crowdsourcing. “Because in theory it is a total disaster.” Wikipedia works in practice, and not in theory. It’s a popular idiom among Wikipedians, as \u003ca href=\"https://www.colorado.edu/cmci/people/information-science/brian-c-keegan\"\u003eBrian Keegan\u003c/a\u003e writes in \u003ca href=\"https://wikipedia20.pubpub.org/pub/dj6frhgz/release/2\"\u003eWikipedia@20\u003c/a\u003e. And it does suggest there’s something magical about the project, where successful shared editing of a single document has been happening long before Google docs.\u003c/p\u003e\n\u003cp\u003eThere is a logic to Wikipedia—no magic. The free encyclopedia launched in 2001 for “anyone” to edit. This was not an explicit democratic effort to engage portions of the public who have historically been left out of structures of power, though some have championed Wikipedia for getting close to achieving this. Rather, the effort was a wildcard reversal of Wikipedia’s failed predecessor, \u003ca href=\"https://en.wikipedia.org/wiki/Nupedia\"\u003eNupedia\u003c/a\u003e, which was designed as a free, peer-reviewed encyclopedia edited by recognised experts. When shifted from experts to “anyone”—that is, people who happened to have computers, internet connections, a penchant for online debate and were familiar with \u003ca href=\"https://www.mediawiki.org/wiki/MediaWiki\"\u003eMediaWiki\u003c/a\u003e, as opposed to busy academic experts—contributions flowed faster. \u003c/p\u003e\n\u003cp\u003eWikipedia was also a product of its time. It was one of many online encyclopedia projects in the early 2000s. According to the \u003ca href=\"https://www.law.cornell.edu/uscode/text/47/230\"\u003eSection 230\u003c/a\u003e of the \u003ca href=\"https://www.law.cornell.edu/uscode/text/47/230\"\u003e1996 Computer Decency Act in the United States\u003c/a\u003e, Wikipedia, like other platforms then and now, has been immune from legal liability for contents. \u003ca href=\"https://www.law.cornell.edu/uscode/text/47/230\"\u003eSection 230\u003c/a\u003e also gives platforms the legal blessing to govern as they see fit. Jimmy Wales, co-founder of Wikipedia, set up the Wikimedia Foundation to oversee the project and sister platforms in 2005, and it has remained volunteer-run. The Wikimedia Foundation has an endowment of more than 64 million, with tech titans such as \u003ca href=\"https://wikimediafoundation.org/news/2020/09/25/amazon-donates-1-million-gift/\"\u003eAmazon pledging millions\u003c/a\u003e, and the Foundation supports projects by volunteers and affiliates. English Wikipedia has snowballed in popularity on a commercial internet. Google, for instance, prioritises Wikipedia articles in search results—treats them like “gospel” said Cohen, while the \u003ca href=\"https://firstmonday.org/article/view/2830/2476\"\u003econvenience, currency, and comprehensibility\u003c/a\u003e of Wikipedia attracts regular readers.\u003c/p\u003e\n\n                                                                      \n                            \u003ch2\u003eUsing pageviews to tell a story\u003c/h2\u003e\n\u003cp\u003eData journalists can find the granular level of insight about pageviews handy for storytelling. Viewers of Wikipedia come from around the world. The Wikimedia Foundation does not track individual data, but tracks devices across pages. Data about what type of device—mobile app, mobile browser, or desktop browser—are used to access pages. This can give journalists insight into topical and regional access trends. \u003c/p\u003e\n\u003cp\u003eMore radically, pageviews can reveal kernels of stories yet to be broken. Let’s simulate research using pageviews for a story on the rising COVID-19 case count in light of concerns about circulation of misinformation and disinformation on the virus. Digging into pageview data on COVID-19 articles in English Wikipedia can help to tell this story, and others like it. \u003c/p\u003e\n\u003cp\u003eIn spring 2020, as unprecedented economic and social changes unfolded across the globe, journalists were at the forefront of providing coverage on this moment. Meanwhile, conspiracy theories were gaining visibility in social media groups, while edit counts and information queries about all articles related to COVID-19 were at their highest to date. \u003c/p\u003e\n\u003cp\u003eBy mid-November 2020, a new trend. Positive cases of COVID-19 skyrocketed around the globe. Several European countries and U.S. states re-introduced lockdown measures to slow the spread of the virus. But Wikipedia pageviews for articles about COVID-19 were not rising, in fact, they were lower than earlier in the year. The election pageviews on the presidential candidates and their families were cresting with the U.S. election.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eA line graph above shows a pageview analysis from Nov 2019 to Oct. 2020 (x axis) depicting pageviews by the thousands (y axis) of four article pages: Donald_Trump, Coronavirus_disease_2019, Joe_Biden, and George_Floyd. Source: \u003ca href=\"https://pageviews.toolforge.org/?project=en.wikipedia.org\u0026amp;platform=all-access\u0026amp;agent=user\u0026amp;redirects=0\u0026amp;start=2019-11\u0026amp;end=2020-10\u0026amp;pages=Donald_Trump|Coronavirus_disease_2019|Joe_Biden|George_Floyd\"\u003epageviews.toolforge.org/\u003c/a\u003e\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eDid election coverage distract readers from the pandemic? Spikes in readership on Wikipedia are often the consequence of other media attention or events, which could help to explain for the peaks in views for George Floyd, Donald Trump and Joe Biden. \n\u003ca href=\"https://www.jackiekoerner.com/\"\u003eKoerner\u003c/a\u003e, who trained as a social scientist, cautions journalists not to make quick deductions about readers' motivations from high-level pageview data. “It’s tricky to say that pageviews are indicative of what people are thinking,” she said. To dig into more granularity, journalists can dig in and compare sets of pageviews using the browser-optimised \u003ca href=\"https://pageviews.toolforge.org/?project=en.wikipedia.org\u0026amp;platform=all-access\u0026amp;agent=user\u0026amp;redirects=0\u0026amp;range=latest-20\u0026amp;pages=Coronavirus_disease_2019|Donald_Trump|Joe_Biden\"\u003epageview visualisation tool\u003c/a\u003e available.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eAbove is a blue bar graph showing pageviews to the Symptoms of COVID-19 article page rising from October to November 22, 2020 (x axis) by the hundreds (y axis). \u003ca href=\"https://pageviews.toolforge.org/?project=en.wikipedia.org\u0026amp;platform=all-access\u0026amp;agent=user\u0026amp;redirects=0\u0026amp;start=2020-10-01\u0026amp;end=2020-11-22\u0026amp;pages=Symptoms_of_COVID-19\"\u003ePageviews to the Symptoms of COVID-19\u003c/a\u003e rose by hundreds in under two months.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eMeanwhile, pageviews of the COVID-19 general article may have peaked in the spring, but data journalists can note that pageviews of the article “Symptoms of the coronavirus” rose in October, as depicted above, before the peaking case numbers. Incidentally, this correlation could lend credence to the suggestion by a team of epidemiologists in 2014 that \u003ca href=\"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003581\"\u003ehigh pageview data about influenza-related Wikipedia articles\u003c/a\u003e could be used to make predictions about the percentage of Americans with influenza. While it remains to be seen if pageviews can predict illness spikes, the data can offer a wide lens on the zeitgeist.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eAbove is a list of the top 10 most viewed articles in 2019, in order of popularity, with lists of the number of edits and editors. Avengers: Endgame, Deaths in 2019, Wikipedia, Ted Bundy, Freddie Mercury, Chernobyl Disaster, and List of Highest-grossing films are top seven. Wikimedia Statistics provide high-level data on trends in pageviews, including top-viewed article pages. \u003ca href=\"https://pageviews.toolforge.org/topviews/?project=en.wikipedia.org\u0026amp;platform=all-access\u0026amp;date=2019\u0026amp;excludes=\"\u003eThe data was accessed at Pageviews.toolforge.org\u003c/a\u003e.\u003c/p\u003e\n\n                                                                      \n                            \u003ch2\u003eBehind the scenes\u003c/h2\u003e\n\u003cp\u003eWith approximately 300 edits per minute—which is \u003ca href=\"http://listen.hatnote.com/\"\u003esoothing to listen to\u003c/a\u003e—Wikipedia is always changing. You may already have edited Wikipedia, the blue “edit” tab is on almost every article page. There are \u003ca href=\"https://en.wikipedia.org/wiki/List_of_languages_by_total_number_of_speakers#cite_ref-6\"\u003emore than 1.2 billion speakers\u003c/a\u003e of English and over 40 million Wikipedia accounts.\u003c/p\u003e\n\u003cp\u003eMaybe you made an account and your changes stuck. Maybe you tried to write an article, only to have it deleted. Or maybe you wondered about how easy it is to add profanity to an article on a popular topic—only to realise that the “Edit” tab is missing. Rather, there’s a lock. Or possibly, a gold star. \u003c/p\u003e\n\u003cp\u003eLocks. Gold stars. Deletions. These are subtle signs and signals that can help you understand how the editing community works.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eAbove is a labelled diagram of the parts of a Wikipedia page using the example of the Black Lives Matter article. While every article page has these features, I've chosen to label the Black Lives Matter article because it is an extensive composite of the movement's history, it's been peer-reviewed by editors and is locked, which makes vandalism more difficult.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eWikipedia’s “best” are marked with green crosses and gold stars, these are Good and Featured content which have undergone “peer review.” They are the minority among Wikipedia's millions, just 0.1%. \u003c/p\u003e\n\u003cp\u003eMeanwhile, the active editorial community on English Wikipedia monthly is about 4,000 editors. Fewer are administrators. As of November 2020, approximately 1,100 users have successfully undergone a “request for administratorship” and have been granted additional technical privileges, including the ability to delete and/or protect pages.  Non administrative editors, however, may patrol new pages and rollback recent changes. \u003c/p\u003e\n\u003cp\u003eWikipedia’s editorial judgement can spark justified outrage. \u003c/p\u003e\n\u003cp\u003eJournalist Stephen Harrison covered this recently in his \u003ca href=\"https://web.archive.org/web/20201027185627/https:/slate.com/technology/2020/10/theresa-greenfield-iowa-senate-race-wikipedia-page.html\"\u003eSlate article on the Theresa Greenfield biography\u003c/a\u003e. While archivists, indigenous and feminist communities have noted the reliable source guidelines exclude oral histories, ephemera, and special collections; I am currently co-leading an \u003ca href=\"https://misinfocon.com/reading-together-reliability-and-multilingual-global-communities-3c7e9bc4af03\"\u003eArt+Feminism research project\u003c/a\u003e on marginalised communities and reliable source guidelines, funded by \u003ca href=\"https://www.wikicred.org/\"\u003eWikiCred\u003c/a\u003e which supports research, software projects and Wikimedia events on information reliability and credibility. Data journalists can follow debates on-wiki, and note what is absent, by looking at article Talk and View history tabs, and on notice boards for \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Articles_for_deletion\"\u003edeletion\u003c/a\u003e and \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources/Noticeboard\"\u003ereliable sources\u003c/a\u003e. \u003c/p\u003e\n\u003cp\u003eAt the same time, there’s plenty to be discovered with Wikipedia. Article features such as wikilinks, citations, and categories can help data journalists quickly access a living repository of information.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eAbove is a labelled diagram showing the wikilinks, citations, and categories using the example of the Black Lives Matter article. On Wikipedia, hyperlinks within articles generally lead to other Wikipedia articles, citations are footnotes with references listed at the end of an article. Categories may help journalists find other articles.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eIn 2011, an editor began a list that documented people killed by law enforcement in the United States, both on duty and off duty. Since 2015, the annual average number of justifiable homicides reported was estimated to be near 930. \u003ca href=\"https://en.wikipedia.org/wiki/Lists_of_killings_by_law_enforcement_officers_in_the_United_States\"\u003eTables about gun violence\u003c/a\u003e, have been collected on Wikipedia for nearly a decade.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eAbove shows a diagram of portions of the article list of killings by law enforcement officers in the United States, including a monthly table from pre-2009 to 2020. This Wikipedia list has amassed data sets from hundreds of sources that verify the killing of humans by law enforcement officers. Between 930 and 1,240 people are killed by police annually in the United States.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eThe integrity of this list was brought to my attention by \u003ca href=\"http://www.jennifer8lee.com/\"\u003eJennifer 8. Lee\u003c/a\u003e, a former New York Times journalist. She expressed surprise that there are not more examples of journalists using Wikipedia’s data. Lee would know, she co-founded the U.S.-based \u003ca href=\"https://credibilitycoalition.org/\"\u003eCredibility Coalition\u003c/a\u003e and \u003ca href=\"https://misinfocon.com/\"\u003eMisinfoCon\u003c/a\u003e, and supports \u003ca href=\"https://www.wikicred.org/#-1\"\u003eWikiCred\u003c/a\u003e, which addresses credibility in online information and includes Wikipedians, technologists, and journalists.\u003c/p\u003e\n\u003cp\u003e“[These] are fascinating and useful,” said Lee. “Not automated, this is a hand-written list. It’s all in one place. This is useful for journalists and those of us in the credibility sphere to use it for research.” \u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://wikimediafoundation.org/news/author/eerhart/\"\u003eEd Erhart\u003c/a\u003e, who works with the Wikimedia Foundation’s audience engagement team, suggests that stories can not only be a repository but fodder for coverage. “I like to say that there is a story in every Wikipedia article,” he wrote by email, drawing my attention to a Featured article about a small town, \u003ca href=\"https://en.wikipedia.org/wiki/Arlington,_Washington\"\u003eArlington, Washington\u003c/a\u003e. “Who wrote it? Where are they from? What motivated them? The talk and history tabs on Wikipedia's pages can be the starting point for some truly unique takes on local places and issues.”\u003c/p\u003e\n\n                                                                                                 \u003cp\u003e\u003cstrong\u003eQuick links\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eVisit \u003ca href=\"https://pageviews.toolforge.org/?project=en.wikipedia.org\u0026amp;platform=all-access\u0026amp;agent=user\u0026amp;redirects=0\u0026amp;range=latest-20\u0026amp;pages=Cat|Dog\"\u003epageview statistics homepage\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eMore about \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Protection_policy\"\u003epage protection\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eMore about \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:User_access_levels\"\u003euser access levels\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eMore about \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Featured_articles\"\u003efeatured articles\u003c/a\u003e and \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Featured_lists\"\u003elists\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eIcon for featured articles is a star\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eIcon for good articles is a green circle with a plus sign\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n                                                                     \n                            \u003ch2\u003eCatching malfeasance\u003c/h2\u003e\n\u003cp\u003eData journalists can follow edits to track corporate or governmental malfeasance. Article pages about companies or politicians can be scrubbed to omit negative information. Though editors are required to disclose conflicts of interest on their user page or in the \u003ca href=\"https://en.wikipedia.org/wiki/Wikipedia:Conflict_of_interest#How_to_disclose_a_COI\"\u003eArticle's talk page\u003c/a\u003e.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eUsers who edit Wikipedia as a part of their paid work are required to disclose conflicts of interest. This image shows an example of a user who has done so. John P. Sadowski edits articles on biomedical topics, including articles related to COVID-19, using resources from his employer, the U.S. Center for Disease Control (CDC). Not all contributors do this.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eNot all contributors disclose. \u003ca href=\"https://scholar.google.com/citations?user=oAUwQCEAAAAJ\u0026amp;hl=en\"\u003eKaylea Champion\u003c/a\u003e, a doctoral student at the University of Washington, led a large scale research project on IP editing and \u003ca href=\"https://dl.acm.org/doi/10.1145/3359155?cid=81100401804\"\u003ediscovered systematic deletions to mining articles\u003c/a\u003e. Anonymous editors removed information about environmental contamination and abuse. Champion and her co-authors traced the IP addresses that deleted the incriminating information to the headquarters of the mining companies. \u003c/p\u003e\n\u003cp\u003eJournalists can do their own large-scale reconstructions of edit histories using data from Wikipedia’s \u003ca href=\"https://dumps.wikimedia.org/\"\u003edata dump\u003c/a\u003e, or manually browse pages of interest. Historical contributions can all be accessed, even if they are not visible on the live page. As well, journalists can reach out to editors by writing a note on their Talk page with information on how to connect.\u003c/p\u003e\n\u003cp\u003eThe below GIF demonstrates how to access View History and compare versions of the Black Lives Matter article page, using the Compare Version History tool. Be sure to use the View History tab to compare version histories, which is shown above. You can also click on the timestamp to view an article in full.\u003c/p\u003e\n\n                                                                                                                                             \u003cp\u003e\u003cstrong\u003eQuick links\u003c/strong\u003e \u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://wikimedia.org/api/rest_v1/#/Pageviews_data/get_metrics_\"\u003eWikipedia’s API\u003c/a\u003e \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://dumps.wikimedia.org/\"\u003eData dumps\u003c/a\u003e with complete copies of all Wikipedias\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n                                                                     \n                            \u003ch2\u003eTracking with bots\u003c/h2\u003e\n\u003cp\u003eBots can help with tracking. In 2014, a number of bots were launched by volunteers to track edits made by specific IP ranges and posted the findings to Twitter. \u003ca href=\"https://twitter.com/parliamentedits\"\u003eParliament WikiEdits\u003c/a\u003e, one of the first, still regularly tweets edits made to Parliamentary IPs in the UK. Similar efforts have been available for \u003ca href=\"https://twitter.com/whitehousedits\"\u003eThe White House\u003c/a\u003e, \u003ca href=\"https://twitter.com/euroedit\"\u003eEuropean Union\u003c/a\u003e, \u003ca href=\"https://twitter.com/wikistorting\"\u003eNorwegian Parliament\u003c/a\u003e, \u003ca href=\"https://twitter.com/bundesedit\"\u003eGerman Parliament\u003c/a\u003e, Goldman Sachs and Monsanto Company, though not all are up to date. \u003c/p\u003e\n\u003cp\u003eFor data journalists interested in setting up a bot that tweets about anonymous Wikipedia edits from particular IP address ranges in their beat, \u003ca href=\"https://github.com/edsu/anon\"\u003ethe code is available\u003c/a\u003e from Ed Summers on GitHub under a CC0 license.\u003c/p\u003e\n\n                                                                                                 \u003cblockquote\u003e\u003cp\u003eData journalists should weigh the public benefit of amplifying hate speech, harassment, or vandalism, which could be a form of coded language, with reporting.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003ch2\u003ePitfalls to avoid: steering clear of media manipulation\u003c/h2\u003e\n\u003cp\u003eSummers created @CongressEdits in 2014, which tweeted IP contributions from U.S. capitol computers. \u003ca href=\"http://thewikipedian.net/2019/01/17/congressedits-twitter-suspended/\"\u003eThe Wikipedian\u003c/a\u003e reported that “Twitter-addicted journalists” soon were mining the bots for story ideas -- some of which did reveal manipulation, such as an attempt to water down \u003ca href=\"https://mashable.com/2014/12/10/senate-wikipedia-torture-report/?europe=true#YgOIf16EJkqN\"\u003ethe entry on CIA torture\u003c/a\u003e. @CongressEdits amassed a growing audience.  Things came to a head in 2018. \u003ca href=\"https://www.washingtonpost.com/local/public-safety/democratic-ex-staffer-contests-charges-he-posted-personal-data-on-gop-senators-threatened-witness-in-doxing/2018/10/04/88842844-c806-11e8-b2b5-79270f9cce17_story.html\"\u003eA former Democratic staffer\u003c/a\u003e (who was later arrested) with access to the U.S. capitol computers inserted personal information to Wikipedia articles about Republican members of the Senate Judiciary Committee. The Twitter account automatically shared out those details with the large following. \u003ca href=\"http://thewikipedian.net/2019/01/17/congressedits-twitter-suspended/\"\u003eTwitter banned the bot as a result\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePeople can intentionally game the editorial system or interconnections between Wikipedia and other social media platforms. Data journalists should weigh the public benefit of amplifying hate speech, harassment, or vandalism, which could be a form of coded language, with reporting. “Why are people editing articles to say that the [mainstream political party] is [name of radical, violent party]? They want the screenshot,” Cohen remarked. “The best way to get a lie into [the] mainstream is to edit an article, let Google pick it up, and get reporting on it. It’s probably a thrill to plant them.”\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eFurthermore, Wikipedia has no “real name” policy for editors. Some choose to disclose personal details on user pages, which can help gain the confidence of other editors, but this is not required. Thus, manipulators can mimic the behaviour patterns of a group to blend in.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.hks.harvard.edu/faculty/joan-donovan\"\u003eJoan Donovan\u003c/a\u003e, director of Technology and Social Change at \u003ca href=\"https://shorensteincenter.org/\"\u003eHarvard Kennedy School’s Shorenstein Center\u003c/a\u003e, calls this a \u003ca href=\"https://www.theatlantic.com/ideas/archive/2019/03/extremists-understand-what-tech-platforms-have-built/585136/\"\u003e“butterfly attack.”\u003c/a\u003e Once the fakes are indistinguishable to outsiders from legitimate accounts, the manipulators push contentious issues to divide and delegitimise the group. Be mindful that you are not also falling for a “butterfly attack”—or perpetuating one by accidentally characterising editors as occupying one particular position over another. Instead, get to know the communities behind the data to minimise harm.  \u003c/p\u003e\n\u003cp\u003eIf you discover vandalism or hate-speech on a page history, consider the impact of your coverage on a topic that has since disappeared. Be mindful of the extent to which the effort at public service can dually serve as a form of publicity or exposure for people sympathetic with fringe ideologies or violence. Reporters who stumble across data on hate-speech might report on this in aggregate, without identifying particular details, to minimise harm.\u003c/p\u003e\n\n                                                                                                 \u003cp\u003e\u003cstrong\u003ePro tips for navigating Wikipedia:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eGet to know Wikipedia’s editorial process and community before reporting on hate speech or harassment\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eStrongly consider the newsworthiness of articles that might give publicity to fringe ideologies\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eUse data in aggregate to avoid revealing details\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n                                                                     \n                            \u003ch2\u003eCircular reporting\u003c/h2\u003e\n\u003cp\u003eIn 2007, \u003ca href=\"https://www.independent.co.uk/\"\u003eThe Independent\u003c/a\u003e published an article on \u003ca href=\"https://www.independent.co.uk/arts-entertainment/comedy/news/baron-cohen-comes-out-of-character-to-defend-borat-424656.html\"\u003eSasha Baron Cohen\u003c/a\u003e that included a line that he had previously worked as an investment banker. Days earlier, \u003ca href=\"https://en.wikipedia.org/w/index.php?title=Sacha_Baron_Cohen\u0026amp;type=revision\u0026amp;diff=87679263\u0026amp;oldid=87661979\"\u003ethe claim had appeared in Wikipedia\u003c/a\u003e, and was unverified. Later, The Independent’s article became the citation for the erroneous claim. \u003c/p\u003e\n\u003cp\u003eNone of it was true. And Wikipedia editors call incidents like this “citogenesis,” or circular reporting. There is even a Wikipedia \u003ca href=\"https://en.wikipedia.org/wiki/Circular_reporting#Examples_involving_Wikipedia\"\u003earticle that compiles known instances\u003c/a\u003e. \u003ca href=\"https://techdebug.com/blog/2008/04/19/wikipedia-article-creates-circular-references/\"\u003eTechdebug blog\u003c/a\u003e depicted the Baron Cohen example with the good advice to “pay attention to timelines” when reviewing sources of claims on Wikipedia. When using facts from Wikipedia, trust but verify.\u003c/p\u003e\n\u003cp\u003eWith close attention to detail and context, data journalists can use Wikipedia’s trove of data to elucidate stories of the digital landscape. “Wikipedia is more than the sum of its parts” said Cohen. “Random encounters are often more compelling than the articles themselves. The search for information resembles a walk through an overbuilt quarter of an ancient capital. You circle around topics on a path that appears to be shifting. Ultimately, the journey ends and you are not sure how you got there.”\u003c/p\u003e\n\n                                                                                                                                 \u003cp\u003eMonika Sengul-Jones, PhD, is a freelance researcher, writer and expert on digital cultures and media industries. She was the OCLC Wikipedian-in-Residence in 2018-19. In 2020, she is co-leading \u003ca href=\"https://artandfeminism.org/initiatives/current-initiatives/reading-together/\"\u003eReading Together: Reliable Sources and Multilingual Communities\u003c/a\u003e, an Art+Feminism project on reliable sources and marginalised communities funded by WikiCred. \u003ca href=\"https://twitter.com/monikajones\"\u003e@monikajones\u003c/a\u003e, \u003ca href=\"https://monikasjones.com\"\u003ewww.monikasjones.com\u003c/a\u003e\u003c/p\u003e\n\n                                                                                                                              \n                            \u003cp\u003eThanks to Mohammed Sadat Abdulai (Art+Feminism, Wikimedia Deutschland), Ahmed Median (Hack/Hackers), and Kevin Payravi (WikiCred, Wikimedia D.C.), and for taking time to interview with me for background research for this story.\u003c/p\u003e\n\n                                                                      \n                            \u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://datajournalism.com/read/longreads/data-visualisation-by-hand\"\u003eData visualisation by hand: drawing data for your next story\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://datajournalism.com/read/longreads/hypothesis-data-journalism\"\u003eA data journalists guide to building a hypothesis\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://datajournalism.com/read/longreads/the-promise-of-wikidata\"\u003eThe promise of WikiData as a data source for journalists\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://datajournalism.com/read/longreads/data-sonification\"\u003eMaking numbers louder: telling stories with sound\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://datajournalism.com/read/longreads/conflict-reporting-with-data\"\u003eConflict reporting with data\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://datajournalism.com/read/longreads/own-your-newsfeed-own-your-data\"\u003eOwn your newsfeed, own your data\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n                                              \n                ","contentSnippet":"Orientations to Wikipedia often begin with its enormity. And it is enormous. The encyclopedia will be 20 years old in January 2021 and has more than 53 million articles in 314 languages. Six million are in English. According to Alexa.com, Wikipedia is the 8th most-visited web domain in the United States, and the 13th globally; it’s the only non-profit in the top-100 domains. In November 2020, more than 1.7 billion unique devices from around the world accessed Wikipedia articles. Average monthly pageviews surpass 20 billion. \nBeyond reach, there’s the data. All data on and about all Wikipedias—from pageview statistics, most-frequently cited references, to access to every version ever written and all the editors who have ever contributed to it—is freely available. Entire version histories are available at dumps.wikimedia.org.\nTwitter bots that share edited Wikipedia entries text from high impact IP addresses, such as the White House, which is covered by the @whitehouseedits bot, pictured above, can help data journalists track malfeasance. But there’s evidence the bots can be manipulated. Image credit: Twitter @Whitehousedits\nThanks to the free and open access to billions of human and machine-readable data, corporations and research centres have been leveraging Wikipedia for research for years. Benjamin Mako Hill, assistant professor of communication at the University of Washington and Aaron Shaw, associate professor of communication at Northwestern University, describe Wikipedia as the “most important laboratory for social scientific and computing research in history” in their chapter in \"Wikipedia@20\", a new book on Wikipedia published by MIT Press, edited by Joseph Reagle and Jackie Koerner. \n“Wikipedia has become part of the mainstream of every social and computational research field we know of,” Hill and Shaw write. Google’s knowledge graph and smart AI technologies, such as Amazon’s Alexa and Google Home, are based on metadata from Wikimedia projects, of which Wikipedia is the best-known. Significant for data journalists is how Wikipedia’s influence has already surpassed clicks to article pages; in a way, the internet is already Wikipedia’s world, we’re just living in it.\nBut journalists know well that ubiquity shouldn’t stand in for universality. We should be mindful that indiscriminate use of “big data” without acknowledging context reproduces what Joy Buolamwini, founder of the Algorithmic Justice League, calls the “coded gaze” of white data. Safiya Umoja Noble, a critical information studies expert and associate professor at UCLA, challenges the acceptance of invisible values that normalise algorithmic hierarchies. \nInternet search results, which often prioritise Wikipedia articles in addition to using Wikipedia’s infobox data or structured data in sidebars, “feign impartiality and objectivity in the process of displaying results” Noble writes in \"Algorithms of Oppression: How Search Engines Reinforce Racism\". \nSystemic biases on Wikipedia, including well-documented “gaps” in coverage, readership, and source, are cause for pause. Globally, volunteer contributors are predominately white males from the northern hemisphere. On English Wikipedia, less than 20% of editors self-identify as female. Asymmetries in participation have impacted the editorial processes and content. Editors who self-identify as women often perform “emotional work” to justify their contributions. Women and nonbinary users on Wikipedia may encounter hostile, violent language and some have experienced harassment and doxing. Then there are the asymmetries in the breadth and depth of coverage; only approximately 17% of biographies on English Wikipedia are about women.\n How to contribute to Wikipedia\nAnyone can edit Wikipedia, but there is an editorial pecking order and policies to keep in mind. Tips for success:\nAssuming you have created an account, be sure to include a bio on your user page (you don't need to use your real name, but you can).\nImprove existing articles to begin, you can create new articles once your account is four days old and you’ve made ten edits.\nInclude verifiable citations to secondary sources for any new claims--or claims where a citation is needed.\nBe aware of Wikipedia’s guidelines on conflicts of interest.\nBeyond this, there are many tutorials and videos with various tips and tricks. Among them, this is a useful high-level summary, while an editing tutorial hosted by the Wikimedia Foundation walks you through nitty-gritty basics.\nWith this glut of imperfect or missing data, what’s a data journalist to do? Journalists doing internet research might consider that they are already knee-deep in a minefield of constraints. \n“The reality for journalists working on the internet is fraught,” said Hill. “Most internet data sets are controlled by commercial companies. That means there’s never going to be a full data set and what’s available has been—or is being—manipulated. Wikipedia is different. It’s free, it’s accessible, and it’s from a public service organisation.” Like any institution, as Catherine D’Ignazio has pointed out in this publication, context may be hard to find. On Wikipedia, that’s often due to the decentralised organisation of open source projects; volunteers come and go, rather than intentional obfuscation.  \nNevertheless, Noam Cohen, a journalist for Wired and The New York Times who has written about Wikipedia for nearly two decades, said in a phone interview that journalists should—if they are not already—use Wikipedia’s data, including pageviews and the layers of information found in article pages. But Cohen cautions journalists not to let Wikipedia’s decisions on coverage replace news judgement. “In journalism, word length is often a sign of importance,” Cohen said. “That’s not the case on Wikipedia, there are articles about \"The Simpsons\" or characters on \"Lost\" that are longer than articles about important women scientists or philosophers. But these trends don’t mean there are not rules. There are, the information is changing.”\nTo leverage Wikipedia’s superpowers for data journalism, it’s best to climb into the belly of the beast.\nLast year, Cohen’s editor asked him to write about why his Wikipedia biography—which he did not create, there are guidelines barring “conflict of interest editing”—was deleted. Cohen dug in and discovered it was due to “sock-puppetry;” that’s shorthand for editors who use more than one account without disclosure. Later, another editor restored Cohen’s biography. \nStories like this may give journalists discomfort about the contingencies of the online encyclopedia, and any data sets therein. And for as long as there’s been Wikipedia, there have been editors and professors warning us to stay away. But Cohen suggests thinking otherwise. “The fact that information is slowly being changed and is always saved is Wikipedia’s superpower,” said Cohen. To leverage Wikipedia’s superpowers for data journalism, it’s best to climb into the belly of the beast.\nUnderstand how Wikipedia’s authority works\nWhile one might reasonably guess that The Wikipedia Foundation manages editorial oversight, that’s not the case. All content decisions, including developing and managing bots to do tedious, repetitive tasks—fixing redirects or reverting vandalism, as ClueBot_NG does—are designed and run by volunteers. The Wikipedia community has developed a number of policies and guidelines to govern editing, including a rule about verifiability and a blacklist of publications not allowed to be cited on Wikipedia. Blacklisted publications include spam and publications that do not fact check and circulate conspiracy theories.\nIn 2017, Katherine Maher, executive director of The Wikimedia Foundation, spoke with The Guardian about the volunteer community’s decision to blacklist The Daily Mail as a reliable source. “It’s amazing [Wikipedia] works in practice,” she said, motioning to a concept that academics have called peer-production or crowdsourcing. “Because in theory it is a total disaster.” Wikipedia works in practice, and not in theory. It’s a popular idiom among Wikipedians, as Brian Keegan writes in Wikipedia@20. And it does suggest there’s something magical about the project, where successful shared editing of a single document has been happening long before Google docs.\nThere is a logic to Wikipedia—no magic. The free encyclopedia launched in 2001 for “anyone” to edit. This was not an explicit democratic effort to engage portions of the public who have historically been left out of structures of power, though some have championed Wikipedia for getting close to achieving this. Rather, the effort was a wildcard reversal of Wikipedia’s failed predecessor, Nupedia, which was designed as a free, peer-reviewed encyclopedia edited by recognised experts. When shifted from experts to “anyone”—that is, people who happened to have computers, internet connections, a penchant for online debate and were familiar with MediaWiki, as opposed to busy academic experts—contributions flowed faster. \nWikipedia was also a product of its time. It was one of many online encyclopedia projects in the early 2000s. According to the Section 230 of the 1996 Computer Decency Act in the United States, Wikipedia, like other platforms then and now, has been immune from legal liability for contents. Section 230 also gives platforms the legal blessing to govern as they see fit. Jimmy Wales, co-founder of Wikipedia, set up the Wikimedia Foundation to oversee the project and sister platforms in 2005, and it has remained volunteer-run. The Wikimedia Foundation has an endowment of more than 64 million, with tech titans such as Amazon pledging millions, and the Foundation supports projects by volunteers and affiliates. English Wikipedia has snowballed in popularity on a commercial internet. Google, for instance, prioritises Wikipedia articles in search results—treats them like “gospel” said Cohen, while the convenience, currency, and comprehensibility of Wikipedia attracts regular readers.\nUsing pageviews to tell a story\nData journalists can find the granular level of insight about pageviews handy for storytelling. Viewers of Wikipedia come from around the world. The Wikimedia Foundation does not track individual data, but tracks devices across pages. Data about what type of device—mobile app, mobile browser, or desktop browser—are used to access pages. This can give journalists insight into topical and regional access trends. \nMore radically, pageviews can reveal kernels of stories yet to be broken. Let’s simulate research using pageviews for a story on the rising COVID-19 case count in light of concerns about circulation of misinformation and disinformation on the virus. Digging into pageview data on COVID-19 articles in English Wikipedia can help to tell this story, and others like it. \nIn spring 2020, as unprecedented economic and social changes unfolded across the globe, journalists were at the forefront of providing coverage on this moment. Meanwhile, conspiracy theories were gaining visibility in social media groups, while edit counts and information queries about all articles related to COVID-19 were at their highest to date. \nBy mid-November 2020, a new trend. Positive cases of COVID-19 skyrocketed around the globe. Several European countries and U.S. states re-introduced lockdown measures to slow the spread of the virus. But Wikipedia pageviews for articles about COVID-19 were not rising, in fact, they were lower than earlier in the year. The election pageviews on the presidential candidates and their families were cresting with the U.S. election.\nA line graph above shows a pageview analysis from Nov 2019 to Oct. 2020 (x axis) depicting pageviews by the thousands (y axis) of four article pages: Donald_Trump, Coronavirus_disease_2019, Joe_Biden, and George_Floyd. Source: pageviews.toolforge.org/\nDid election coverage distract readers from the pandemic? Spikes in readership on Wikipedia are often the consequence of other media attention or events, which could help to explain for the peaks in views for George Floyd, Donald Trump and Joe Biden. \nKoerner, who trained as a social scientist, cautions journalists not to make quick deductions about readers' motivations from high-level pageview data. “It’s tricky to say that pageviews are indicative of what people are thinking,” she said. To dig into more granularity, journalists can dig in and compare sets of pageviews using the browser-optimised pageview visualisation tool available.\nAbove is a blue bar graph showing pageviews to the Symptoms of COVID-19 article page rising from October to November 22, 2020 (x axis) by the hundreds (y axis). Pageviews to the Symptoms of COVID-19 rose by hundreds in under two months.\nMeanwhile, pageviews of the COVID-19 general article may have peaked in the spring, but data journalists can note that pageviews of the article “Symptoms of the coronavirus” rose in October, as depicted above, before the peaking case numbers. Incidentally, this correlation could lend credence to the suggestion by a team of epidemiologists in 2014 that high pageview data about influenza-related Wikipedia articles could be used to make predictions about the percentage of Americans with influenza. While it remains to be seen if pageviews can predict illness spikes, the data can offer a wide lens on the zeitgeist.\nAbove is a list of the top 10 most viewed articles in 2019, in order of popularity, with lists of the number of edits and editors. Avengers: Endgame, Deaths in 2019, Wikipedia, Ted Bundy, Freddie Mercury, Chernobyl Disaster, and List of Highest-grossing films are top seven. Wikimedia Statistics provide high-level data on trends in pageviews, including top-viewed article pages. The data was accessed at Pageviews.toolforge.org.\nBehind the scenes\nWith approximately 300 edits per minute—which is soothing to listen to—Wikipedia is always changing. You may already have edited Wikipedia, the blue “edit” tab is on almost every article page. There are more than 1.2 billion speakers of English and over 40 million Wikipedia accounts.\nMaybe you made an account and your changes stuck. Maybe you tried to write an article, only to have it deleted. Or maybe you wondered about how easy it is to add profanity to an article on a popular topic—only to realise that the “Edit” tab is missing. Rather, there’s a lock. Or possibly, a gold star. \nLocks. Gold stars. Deletions. These are subtle signs and signals that can help you understand how the editing community works.\nAbove is a labelled diagram of the parts of a Wikipedia page using the example of the Black Lives Matter article. While every article page has these features, I've chosen to label the Black Lives Matter article because it is an extensive composite of the movement's history, it's been peer-reviewed by editors and is locked, which makes vandalism more difficult.\nWikipedia’s “best” are marked with green crosses and gold stars, these are Good and Featured content which have undergone “peer review.” They are the minority among Wikipedia's millions, just 0.1%. \nMeanwhile, the active editorial community on English Wikipedia monthly is about 4,000 editors. Fewer are administrators. As of November 2020, approximately 1,100 users have successfully undergone a “request for administratorship” and have been granted additional technical privileges, including the ability to delete and/or protect pages.  Non administrative editors, however, may patrol new pages and rollback recent changes. \nWikipedia’s editorial judgement can spark justified outrage. \nJournalist Stephen Harrison covered this recently in his Slate article on the Theresa Greenfield biography. While archivists, indigenous and feminist communities have noted the reliable source guidelines exclude oral histories, ephemera, and special collections; I am currently co-leading an Art+Feminism research project on marginalised communities and reliable source guidelines, funded by WikiCred which supports research, software projects and Wikimedia events on information reliability and credibility. Data journalists can follow debates on-wiki, and note what is absent, by looking at article Talk and View history tabs, and on notice boards for deletion and reliable sources. \nAt the same time, there’s plenty to be discovered with Wikipedia. Article features such as wikilinks, citations, and categories can help data journalists quickly access a living repository of information.\nAbove is a labelled diagram showing the wikilinks, citations, and categories using the example of the Black Lives Matter article. On Wikipedia, hyperlinks within articles generally lead to other Wikipedia articles, citations are footnotes with references listed at the end of an article. Categories may help journalists find other articles.\nIn 2011, an editor began a list that documented people killed by law enforcement in the United States, both on duty and off duty. Since 2015, the annual average number of justifiable homicides reported was estimated to be near 930. Tables about gun violence, have been collected on Wikipedia for nearly a decade.\nAbove shows a diagram of portions of the article list of killings by law enforcement officers in the United States, including a monthly table from pre-2009 to 2020. This Wikipedia list has amassed data sets from hundreds of sources that verify the killing of humans by law enforcement officers. Between 930 and 1,240 people are killed by police annually in the United States.\nThe integrity of this list was brought to my attention by Jennifer 8. Lee, a former New York Times journalist. She expressed surprise that there are not more examples of journalists using Wikipedia’s data. Lee would know, she co-founded the U.S.-based Credibility Coalition and MisinfoCon, and supports WikiCred, which addresses credibility in online information and includes Wikipedians, technologists, and journalists.\n“[These] are fascinating and useful,” said Lee. “Not automated, this is a hand-written list. It’s all in one place. This is useful for journalists and those of us in the credibility sphere to use it for research.” \nEd Erhart, who works with the Wikimedia Foundation’s audience engagement team, suggests that stories can not only be a repository but fodder for coverage. “I like to say that there is a story in every Wikipedia article,” he wrote by email, drawing my attention to a Featured article about a small town, Arlington, Washington. “Who wrote it? Where are they from? What motivated them? The talk and history tabs on Wikipedia's pages can be the starting point for some truly unique takes on local places and issues.”\nQuick links\nVisit pageview statistics homepage\nMore about page protection\nMore about user access levels\nMore about featured articles and lists\nIcon for featured articles is a star\nIcon for good articles is a green circle with a plus sign\nCatching malfeasance\nData journalists can follow edits to track corporate or governmental malfeasance. Article pages about companies or politicians can be scrubbed to omit negative information. Though editors are required to disclose conflicts of interest on their user page or in the Article's talk page.\nUsers who edit Wikipedia as a part of their paid work are required to disclose conflicts of interest. This image shows an example of a user who has done so. John P. Sadowski edits articles on biomedical topics, including articles related to COVID-19, using resources from his employer, the U.S. Center for Disease Control (CDC). Not all contributors do this.\nNot all contributors disclose. Kaylea Champion, a doctoral student at the University of Washington, led a large scale research project on IP editing and discovered systematic deletions to mining articles. Anonymous editors removed information about environmental contamination and abuse. Champion and her co-authors traced the IP addresses that deleted the incriminating information to the headquarters of the mining companies. \nJournalists can do their own large-scale reconstructions of edit histories using data from Wikipedia’s data dump, or manually browse pages of interest. Historical contributions can all be accessed, even if they are not visible on the live page. As well, journalists can reach out to editors by writing a note on their Talk page with information on how to connect.\nThe below GIF demonstrates how to access View History and compare versions of the Black Lives Matter article page, using the Compare Version History tool. Be sure to use the View History tab to compare version histories, which is shown above. You can also click on the timestamp to view an article in full.\nQuick links \nWikipedia’s API \nData dumps with complete copies of all Wikipedias\nTracking with bots\nBots can help with tracking. In 2014, a number of bots were launched by volunteers to track edits made by specific IP ranges and posted the findings to Twitter. Parliament WikiEdits, one of the first, still regularly tweets edits made to Parliamentary IPs in the UK. Similar efforts have been available for The White House, European Union, Norwegian Parliament, German Parliament, Goldman Sachs and Monsanto Company, though not all are up to date. \nFor data journalists interested in setting up a bot that tweets about anonymous Wikipedia edits from particular IP address ranges in their beat, the code is available from Ed Summers on GitHub under a CC0 license.\nData journalists should weigh the public benefit of amplifying hate speech, harassment, or vandalism, which could be a form of coded language, with reporting.\nPitfalls to avoid: steering clear of media manipulation\nSummers created @CongressEdits in 2014, which tweeted IP contributions from U.S. capitol computers. The Wikipedian reported that “Twitter-addicted journalists” soon were mining the bots for story ideas -- some of which did reveal manipulation, such as an attempt to water down the entry on CIA torture. @CongressEdits amassed a growing audience.  Things came to a head in 2018. A former Democratic staffer (who was later arrested) with access to the U.S. capitol computers inserted personal information to Wikipedia articles about Republican members of the Senate Judiciary Committee. The Twitter account automatically shared out those details with the large following. Twitter banned the bot as a result.\nPeople can intentionally game the editorial system or interconnections between Wikipedia and other social media platforms. Data journalists should weigh the public benefit of amplifying hate speech, harassment, or vandalism, which could be a form of coded language, with reporting. “Why are people editing articles to say that the [mainstream political party] is [name of radical, violent party]? They want the screenshot,” Cohen remarked. “The best way to get a lie into [the] mainstream is to edit an article, let Google pick it up, and get reporting on it. It’s probably a thrill to plant them.”\nFurthermore, Wikipedia has no “real name” policy for editors. Some choose to disclose personal details on user pages, which can help gain the confidence of other editors, but this is not required. Thus, manipulators can mimic the behaviour patterns of a group to blend in.\nJoan Donovan, director of Technology and Social Change at Harvard Kennedy School’s Shorenstein Center, calls this a “butterfly attack.” Once the fakes are indistinguishable to outsiders from legitimate accounts, the manipulators push contentious issues to divide and delegitimise the group. Be mindful that you are not also falling for a “butterfly attack”—or perpetuating one by accidentally characterising editors as occupying one particular position over another. Instead, get to know the communities behind the data to minimise harm.  \nIf you discover vandalism or hate-speech on a page history, consider the impact of your coverage on a topic that has since disappeared. Be mindful of the extent to which the effort at public service can dually serve as a form of publicity or exposure for people sympathetic with fringe ideologies or violence. Reporters who stumble across data on hate-speech might report on this in aggregate, without identifying particular details, to minimise harm.\nPro tips for navigating Wikipedia:\nGet to know Wikipedia’s editorial process and community before reporting on hate speech or harassment\nStrongly consider the newsworthiness of articles that might give publicity to fringe ideologies\nUse data in aggregate to avoid revealing details\nCircular reporting\nIn 2007, The Independent published an article on Sasha Baron Cohen that included a line that he had previously worked as an investment banker. Days earlier, the claim had appeared in Wikipedia, and was unverified. Later, The Independent’s article became the citation for the erroneous claim. \nNone of it was true. And Wikipedia editors call incidents like this “citogenesis,” or circular reporting. There is even a Wikipedia article that compiles known instances. Techdebug blog depicted the Baron Cohen example with the good advice to “pay attention to timelines” when reviewing sources of claims on Wikipedia. When using facts from Wikipedia, trust but verify.\nWith close attention to detail and context, data journalists can use Wikipedia’s trove of data to elucidate stories of the digital landscape. “Wikipedia is more than the sum of its parts” said Cohen. “Random encounters are often more compelling than the articles themselves. The search for information resembles a walk through an overbuilt quarter of an ancient capital. You circle around topics on a path that appears to be shifting. Ultimately, the journey ends and you are not sure how you got there.”\nMonika Sengul-Jones, PhD, is a freelance researcher, writer and expert on digital cultures and media industries. She was the OCLC Wikipedian-in-Residence in 2018-19. In 2020, she is co-leading Reading Together: Reliable Sources and Multilingual Communities, an Art+Feminism project on reliable sources and marginalised communities funded by WikiCred. @monikajones, www.monikasjones.com\nThanks to Mohammed Sadat Abdulai (Art+Feminism, Wikimedia Deutschland), Ahmed Median (Hack/Hackers), and Kevin Payravi (WikiCred, Wikimedia D.C.), and for taking time to interview with me for background research for this story.\nData visualisation by hand: drawing data for your next story\nA data journalists guide to building a hypothesis\nThe promise of WikiData as a data source for journalists\nMaking numbers louder: telling stories with sound\nConflict reporting with data\nOwn your newsfeed, own your data","guid":"https://datajournalism.com/read/longreads/harnessing-wikipedias-superpowers-for-journalism","isoDate":"2020-12-02T06:00:00.000Z","blogTitle":"DataJournalism.com"}},"__N_SSG":true},"page":"/[...slug]","query":{"slug":["harnessing-wikipedias-superpowers-for-journalism"]},"buildId":"0XYe7aucOTe3b0iK50JEi","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>