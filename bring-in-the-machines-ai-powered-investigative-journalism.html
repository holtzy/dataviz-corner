<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/203069c7c894df4d.css" as="style"/><link rel="stylesheet" href="/_next/static/css/203069c7c894df4d.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-59c5c889f52620d6.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-f11614d8aa7ee555.js" defer=""></script><script src="/_next/static/chunks/pages/_app-694ee0f2821639fc.js" defer=""></script><script src="/_next/static/chunks/996-eeb5175dbd5dba8f.js" defer=""></script><script src="/_next/static/chunks/36-94b5e24e03efc6db.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...slug%5D-af748dcc13a25fcb.js" defer=""></script><script src="/_next/static/g_JtxhWbqiyn-x4UYiLa0/_buildManifest.js" defer=""></script><script src="/_next/static/g_JtxhWbqiyn-x4UYiLa0/_ssgManifest.js" defer=""></script></head><body><div id="__next"></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"creator":"Monika Sengul-Jones","title":"Bring in the machines: AI-powered investigative journalism","link":"https://datajournalism.com/read/longreads/machine-learning-investigative-journalism","pubDate":"Wed, 01 Dec 2021 07:00:00 +0100","author":"Monika Sengul-Jones","content":"\n                                                                        \u003cp\u003eOodles. Troves. Tsunamis. With data increasingly stored in extraordinary volume, investigative journalists can and have been piloting extraordinary analysis techniques to make sense of these enormous datasets--and, in doing so, hold corporations and governments accountable.\u003c/p\u003e\n\u003cp\u003eThey’ve been doing this with machine learning, which is a subset of artificial intelligence that deepens data-driven reporting. It’s a technique that’s not just useful in an age of big data--but a must. \u003c/p\u003e\n\u003cp\u003eThe unwritten rule about when to use machine learning in reporting is pretty simple. When the humans involved cannot reasonably analyse data themselves--we’re talking hundreds of thousands of lines on a spreadsheet--it’s time to bring in the machines.\u003c/p\u003e\n\n                                                                                                \u003cblockquote\u003e\u003cp\u003eReporters, editors, software engineers, academics working together--that’s where the magic happens.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003ch3\u003eWhat is machine learning?\u003c/h3\u003e\n\u003cp\u003eFor journalists just getting started, it might be comforting to know that machine learning shares many similarities with statistics. It’s also worth noting that the semantics are a point of contention. \u003c/p\u003e\n\u003cp\u003e“Reasonable people will disagree on what to call what we’re doing now,” said Clayton Aldern, senior data reporter at Grist who recently co-reported the award-winning series \u003ca href=\"https://grist.org/abandoned-oil-gas-wells-permian-texas-new-mexico/\"\u003eWaves of Abandonment\u003c/a\u003e which used machine learning to identify misclassified oil wells in Texas and New Mexico.\u003c/p\u003e\n\u003cp\u003eIndeed, a running joke is that “AI sells”--another data journalist referenced \u003ca href=\"https://tineye.com/search/1d48c14f292249dec1ae54b1c22982d175207473?sort=score\u0026amp;order=desc\u0026amp;page=1\"\u003ethis image\u003c/a\u003e to me to make that point.\u003c/p\u003e\n\u003cp\u003eThe sentiment isn’t unfounded. Meredith Broussard, professor, journalist and author of \u003cstrong\u003eArtificial Unintelligence: How Computers Misunderstand the World\u003c/strong\u003e, said in an interview with the Los Angeles Times that “AI” took hold as a catchy name for what was otherwise known as structured machine learning or statistical modelling, in order to expand commercial interest. But there are differences.\u003c/p\u003e\n\u003cp\u003e“For one, we’re not using pen and paper,” said Aldern, who has masters degrees in neuroscience and public policy from the University of Oxford. “We have the computational power to put statistical theories to work.”\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eMeredith Broussard is a professor and journalist who authored \u003ca href=\"https://mitpress.mit.edu/books/artificial-unintelligence\"\u003eArtificial Unintelligence: How Computers Misunderstand the World\u003c/a\u003e.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eThat distinction is crucial, \u003ca href=\"https://interactions.acm.org/archive/view/november-december-2021/the-steep-cost-of-capture\"\u003eargues Meredith Whittaker\u003c/a\u003e, the Minderoo Research Professor at \u003cstrong\u003eNew York University\u003c/strong\u003e and co-founder and director of the \u003cstrong\u003eAI Now Institute\u003c/strong\u003e. \u003c/p\u003e\n\u003cp\u003eSupervised machine learning has become “shockingly effective” at predictive pattern recognition when trained using significant computational power and massive amounts of quality, human-labelled data. “But it is not the algorithm that was a breakthrough: it was what the algorithm could do when matched with large-scale data and computational resources,” Whittaker said.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eThe AI Now Institute at New York University aims to produce interdisciplinary research and public engagement to help ensure that AI systems are accountable to the communities and contexts in which they’re applied.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eScaling hardly means that humans aren’t involved. On the contrary, the effectiveness of machine learning in general, and for journalism, depends not only on access to quality, labelled data and computational resources, but the skills and infrastructural capacities of the people bringing these pieces together. In other words, newsrooms leveraging machine learning for reporting have journalists in the loop every step of the way.\u003c/p\u003e\n\u003cp\u003e“[Machine learning] has a big human component […] it isn’t magic, it takes considerable time and resources,” said \u003cstrong\u003eEmilia Díaz-Struck\u003c/strong\u003e, research editor at \u003cstrong\u003eInternational Consortium of Investigative Journalists (ICIJ)\u003c/strong\u003e, which has used machine learning in investigations for more than five years. “Reporters, editors, software engineers, academics working together--that’s where the magic happens.\"\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003ch3\u003eWhen is machine learning the right tool for the story?\u003c/h3\u003e\n\u003cp\u003eDesigning and running a machine learning programme is a big task--and there are numerous free or reasonably priced training programmes available for journalists and newsrooms to sharpen their skill sets--we describe the process and training options at the end of this article. But how does machine learning fit into the reporting process? Here are a few of the ways.\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003eManaging overload: Clustering to find leads\u003c/h3\u003e\n\u003cp\u003eWhen the International Consortium of Investigative Journalists, a nonprofit newsroom and network of journalists centred in Washington, D.C., obtained the files that would make up \u003ca href=\"https://www.icij.org/investigations/pandora-papers/about-pandora-papers-investigation/\"\u003ePandora Papers\u003c/a\u003e--like the other exposés they’d reported including the Panama Papers, Paradise Papers--initially the sheer amount of information was mind-blowing.\u003c/p\u003e\n\u003cp\u003e“Reporters were overwhelmed,” said Díaz-Struck. Before they could tell stories, they needed to know what was there, and what they didn’t need. To accomplish this, the ICIJ reporters used machine learning to sort and cluster, among other methods. “First, it worked like a spam filter,” said Díaz-Struck, referencing a popular machine learning application, which sometimes uses Bayes’ theorem to determine the probability that an email is either spam or not spam. The task sounds simple but wasn’t easy.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eICIJ used machine learning to help conduct the largest investigation in journalism history, the \u003ca href=\"https://www.icij.org/investigations/pandora-papers/\"\u003ePandora Papers\u003c/a\u003e.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003e“[Miguel Fiandor called it] a sumo fight. Big data on one side, and on the other, all of us, the journalists, reporters, software developers, and editors,” Díaz-Struck said.  \u003c/p\u003e\n\u003cp\u003eEventually, machine learning helped ICIJ cull data into more manageable groupings and together with ICIJ technologies as Datashare and other data analysis approaches, the team handled the big data. In parallel, more than 600 reporters from around the world took on the herculean effort of connecting the dots between reports of tax evasions and dubious financial dealings by hundreds of world leaders and billionaires.\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003ePointing fingers: Naming past misclassifications\u003c/h3\u003e\n\u003cp\u003eAnother popular use of machine learning is to name misclassifications. This was the tact taken in 2015, when Ben Poston, Joel Rubin and Anthony Pesce used machine learning for \u003cstrong\u003eThe Los Angeles Times\u003c/strong\u003e to determine that The Los Angeles Police Department misclassified approximately 14,000 serious assaults as minor offences over an eight-year period. The misclassification made the city’s crime levels appear lower than accurate.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eAs far back as 2015, \u003ca href=\"https://www.latimes.com/local/cityhall/la-me-crime-stats-20151015-story.html\"\u003eThe Los Angeles Times\u003c/a\u003e used machine learning to show how the city's police department underestimated the city's crime levels by misclassifying thousands of assaults as minor offences.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eSimilarly, \u003cstrong\u003eBuzzFeed News’\u003c/strong\u003e \u003ca href=\"https://www.buzzfeednews.com/article/peteraldhous/hidden-spy-planes\"\u003einvestigation\u003c/a\u003e of secret surveillance aircraft to hunt drug cartels in Mexico, by reporters Peter Aldhous and Karla Zabludovsky, was a question of classification. The effort, which Aldhous documented in \u003ca href=\"https://www.buzzfeednews.com/article/peteraldhous/hidden-spy-planes\"\u003ea separate BuzzFeed article\u003c/a\u003e and on \u003ca href=\"https://buzzfeednews.github.io/2017-08-spy-plane-finder/\"\u003eGitHub\u003c/a\u003e, used a random forest algorithm, a well-known statistical model for classification, to identify potential surveillance aircraft.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003e\u003ca href=\"https://www.buzzfeednews.com/article/peteraldhous/hidden-spy-planes\"\u003eBuzzFeed News\u003c/a\u003e trained a computer to find secret surveillance aircraft by letting a machine-learning algorithm sift for planes with flight patterns that resembled those operated by the FBI and the Department of Homeland Security.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eAnd misclassification was vital in the \u003cstrong\u003eICIJ’s Implant Files\u003c/strong\u003e. This expansive investigation found that medical devices implanted into people’s bodies--such as vaginal netting, copper coil birth control, breast implants, heart monitors, hip replacements, and so on--were linked to more than 83,000 patient deaths and nearly 2 million injuries. Of patients who died, 2,100 people, or 23% of these deaths, were not reported as deaths but more vaguely classified as “device malfunctions or injuries.”\u003c/p\u003e\n\n                                                                                                                  \n                            \u003cp\u003eChecking the wrong box has grave consequences, including misleading health authorities about when devices are linked to deaths and preventing the regulators from knowing a product merits further review--to the detriment of future patients. Díaz-Struck explained it took her team months to design and fact-check machine learning for this research. In the \u003ca href=\"https://www.icij.org/investigations/implant-files/algorithms-analysis-and-adverse-events-how-icij-used-machine-learning-to-help-find-medical-device-issues/\"\u003emethodology article\u003c/a\u003e, published in 2018, she explains that text mining, clustering, and classification algorithms were all involved.\u003c/p\u003e\n\u003cp\u003eThey went on to use machine learning to make \u003cstrong\u003ea second classification\u003c/strong\u003e, to identify patient gender, an unknown category that was not released by the patient files made available by the Federal Drug Administration in the United States. Many of those who had died or were harmed by implants were women, but not always from “women devices” such as breast implants.\u003c/p\u003e\n\n                                                                                                 \u003cblockquote\u003e\u003cp\u003eSometimes applications of machine learning come out of informal conversations.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003cp\u003eWhat were the numbers? Partnering with researchers at Stanford University, Díaz-Struck’s team painstakingly trained a machine to identify the gender of patients who had been harmed, or died, from an implanted medical device using the presence of pronouns or mention of gendered body parts in the notes section of the reports. \u003c/p\u003e\n\u003cp\u003eAfter six months of effort, the team of nearly a dozen was able to identify the sex of 23% of the patients, of which 67% were women and 33% were men. A key limitation was the quality of the data, said Díaz-Struck. Nevertheless, the effects of this reporting are not only greater transparency but reforms.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003ch3\u003eBy any other name? Predicting misclassifications\u003c/h3\u003e\n\u003cp\u003eSometimes applications of machine learning come out of informal conversations. That’s what happened with the \u003cstrong\u003eGrist and Texas Observer story\u003c/strong\u003e that predicts the number of unused oil and gas wells in the Permian Basin that will likely be abandoned in coming years. It will cost taxpayers a billion dollars. The story began with no talk of predictions, rather, it was an informal chat between Aldern and fellow \u003cstrong\u003eGrist journalist Naveena Sadasivam\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003e“She’s been on the oil beat for ages and when the COVID-19 pandemic hit, the price of oil dropped. It even went briefly negative. When that happens, some of the mom-and-pop companies hit hard times. Would any go bankrupt, she wondered? And what would happen to the wells?” Aldern said. Sadasivam joined \u003cstrong\u003eTexas Observer reporter Christopher Collins\u003c/strong\u003e to find out.\u003c/p\u003e\n\u003cp\u003eLooking over data Sadasivam collected from public records requests, she and Aldern brainstormed “what we could say,” he recalled. They spent time organising it into a structured database, still unsure if there was a story. The dataset features included the production history of all the wells in Texas, plus macroeconomic indicators, employment, geotags, depth, drilling history for decades, and cost of oil over time.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eA collaborative \u003ca href=\"https://grist.org/abandoned-oil-gas-wells-permian-texas-new-mexico/\"\u003eGrist and Texas Observer story\u003c/a\u003e is pictured above.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003e“At one point we asked, could we use this to figure out the future? This was a classification problem: which wells might be abandoned in the next couple years,” Aldern said. “And it’s a perfect question for machine learning.”\u003c/p\u003e\n\u003cp\u003eThe results were damning. They predict 13,000 wells would be reclassified from inactive to abandoned in the next four years, costing taxpayers nearly one billion dollars--not to mention the environmental effects of abandonment. Sadasivam and Collin’s on-the-ground reporting corroborated these findings, based on interviews with experts and ranchers who worried, “no one is coming.”\u003c/p\u003e\n\u003cp\u003eAldern documented the methodology in an article and shared the data and code in a \u003cstrong\u003eGitHub file\u003c/strong\u003e. He also was featured in the \u003ca href=\"https://soundcloud.com/datajournalism/episode-36-conversation-with-clayton-aldern-grist\"\u003eConversations with Data podcast\u003c/a\u003e earlier this year.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eA screenshot from the story's \u003ca href=\"https://github.com/clayton-aldern/abandoned-wells\"\u003eGithub file\u003c/a\u003e.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003ch3\u003eHolding technological black boxes accountable with machine learning\u003c/h3\u003e\n\u003cp\u003eA subversive use of machine learning is holding privatised machine learning accountable. As the commercial rollout of AI has taken hold in the past decade--which has implications for newsrooms as well, which we will document in the second piece in this series--tech companies remain tightlipped about their processes, refusing to allow independent researchers to assess structured machine learning. \u003c/p\u003e\n\u003cp\u003eMeanwhile, algorithmic predictions have been criticised for reproducing inequalities as \u003cstrong\u003eVirginia Eubanks\u003c/strong\u003e, a political science associate professor at the University of Albany, argues in her book \u003cstrong\u003e\"Automating Inequality\"\u003c/strong\u003e; or incentivising--and bankrolling--disinformation campaigns, as \u003ca href=\"https://www.technologyreview.com/2021/11/20/1039076/facebook-google-disinformation-clickbait/\"\u003eKaren Cho reports\u003c/a\u003e.\u003c/p\u003e\n\n                                                                                                 \u003cblockquote\u003e\u003cp\u003eFor data journalists who are new to machine learning, it’s possible to follow along the work of others to learn.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003cp\u003e\u003cstrong\u003eThe Markup\u003c/strong\u003e, led by \u003cstrong\u003eJulia Angwin\u003c/strong\u003e, is a nonprofit newsroom focused exclusively on “watchdog” reporting about Big Tech. Like other newsrooms featured in this story, The Markup leverages machine learning and other data-driven methodologies to reverse engineer the algorithms or identify misclassifications and publish a “show your work” article and release the data and code. \u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eMaddy Varner\u003c/strong\u003e, an investigative journalist at The Markup said in an email that they use machine learning for investigations, including a random forest model in their work on \u003ca href=\"https://themarkup.org/amazons-advantage/2021/10/14/how-we-analyzed-amazons-treatment-of-its-brands-in-search-results\"\u003eAmazon’s treatment of its own brands\u003c/a\u003e, which was also described in a letter from Angwin, a story that took a year to break.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eAbove is a screenshot from The Markup homepage and its latest investigation examining Amazon's treatment of its own brands.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eTransparency builds trust. “It is very important to not just to say what you know but explain why you know it,” said Aldhous, who explained that transparency is a cornerstone value at Buzzfeed News. “The greater the ability to see under the hood of the methods, the better. It is like, this is how it works. This is why we have that number. This is why we think that’s a spy plane.”\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003ch3\u003eNo need to reinvent the robot\u003c/h3\u003e\n\u003cp\u003eIf getting started sounds daunting, one of the benefits of data science is the open-source community, said Aldern. Data journalists share code and training data on GitHub, where other data journalists or data scientists can take a look. \u003c/p\u003e\n\u003cp\u003eDon’t be afraid to copy-paste. Borrow tried and true algorithms for logical regressions or decision trees. For data journalists who are new to machine learning, it’s possible to follow along the work of others to learn. \u003c/p\u003e\n\u003cp\u003eBut reporting won’t be fast. Lucia Walinchus, executive director of the non-profit newsroom \u003cstrong\u003eEye on Ohio\u003c/strong\u003e and a Pulitzer Center grantee, has spent more than six months using machine learning to analyse public records on housing repossession in Ohio. The project seeks to understand, mathematically, what makes land banks repossess some homes that are behind on taxes, but not others.\u003c/p\u003e\n\n                                                                                                 \u003cblockquote\u003e\u003cp\u003eIt's an open secret in any data story that the majority of the work is getting the data into order\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003cp\u003e“It’s the perfect problem for software,” she said. Though machine learning is only part of the story and doesn’t replace investigative on-the-ground research. Her inaugural machine-learning investigation is slated for publication in the coming weeks.\u003c/p\u003e\n\u003cp\u003eResource-strapped newsrooms can consider partnerships with academics or companies. The ICIJ has partnered with Stanford University and independent companies to address particularly gnarly data problems while maintaining journalistic independence--crucial when dealing with sensitive materials for a big story that hasn’t yet been broken. \u003c/p\u003e\n\u003cp\u003eThe ICIJ doesn’t outsource the work of training data to ensure accuracy, though they did use a machine learning tool called Snorkel to help classify text and images. Outsourcing the human work of labelling to platforms such as Amazon’s Mechanical Turk, which relies on humans who are paid pennies, has raised ethical concerns.\u003c/p\u003e\n\u003cp\u003eData journalists can also be mindful of criticism about the costs of partnerships with tech companies, as \u003ca href=\"https://interactions.acm.org/archive/view/november-december-2021/the-steep-cost-of-capture\"\u003eWhittaker writes\u003c/a\u003e. \u003c/p\u003e\n\u003cp\u003eWhen independent journalists or academics need tech companies to access the computational power or intellectual resources to conduct research, those companies get to have the final say on decisions about what work to do, to promote, or discuss. “In the era of big data, journalists are not going to disappear, they are more essential than ever,” said Díaz-Struck.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003ch3\u003eResources to master machine learning\u003c/h3\u003e\n\u003cp\u003eTo ramp up skills, there are free training programmes available. At the \u003cstrong\u003eAssociated Press\u003c/strong\u003e, Aimee Rinehart is leading a new effort to expand local news organisations understanding and use of AI tools and technologies, funded with $750,000 from the \u003cstrong\u003eKnight Foundation’s AI effort\u003c/strong\u003e. News leaders in U.S. newsrooms can take \u003ca href=\"https://www.research.net/r/AP-Local-AI\"\u003ea survey\u003c/a\u003e to inform the curriculum of an online course designed by AP; the survey closes in early December 2021. \u003c/p\u003e\n\u003cp\u003eAfter running the course, AP will partner with five newsrooms to identify opportunities for AI and implement those strategies. This initiative follows on the heels of the \u003cstrong\u003eLondon School of Economics Journalism AI project\u003c/strong\u003e funded by \u003cstrong\u003eGoogle News Initiative\u003c/strong\u003e, which also offered a free course on AI for journalists.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003eJournalists can sign up to data journalism bootcamps run by \u003ca href=\"https://www.ire.org/training/bootcamps/\"\u003eInvestigative Reporters and Editors\u003c/a\u003e.\u003c/p\u003e\n\n                                                                      \n                            \u003cp\u003e\u003cstrong\u003eInvestigative Reporters and Editors\u003c/strong\u003e run \u003ca href=\"https://www.ire.org/training/bootcamps/\"\u003edata journalism bootcamps\u003c/a\u003e to teach hands-on technical skills to turn data into accurate, interesting stories. These trainings are not free, but prices vary based on the size of the newsroom, with scholarships available, as well as discounts for students and freelancers. Programmes support journalists to sharpen basic to advanced skills in spreadsheets, data visualisation and mapping, SQL, and coding in R and Python. Journalists should be members of IRE to enrol.\u003c/p\u003e\n\u003cp\u003eData journalists can bootstrap their own training program by learning from and participating in machine learning competitions based on over 50,000 datasets, run by \u003ca href=\"https://www.kaggle.com/competitions\"\u003eKaggle\u003c/a\u003e. While not specifically designed for journalists, the competitions can be valuable and come with three-figure prizes (in U.S. dollars). A Google account is required.\u003c/p\u003e\n\n                                                                                                 \u003ch3\u003eHow it works: Machine learning in a nutshell\u003c/h3\u003e\n\u003cp\u003eLet's run through the machine learning process. The basic tasks include the following:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e1. Assemble data.\u003c/strong\u003e \"It's an open secret in any data story that the majority of the work is getting the data into order,\" said Aldern. Data can be public, garnered from public records requests, scraped, or shared from an external source. Consider the questions you'd like to use the data to answer.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e2. Identify labels and features of some data to build a statistical model.\u003c/strong\u003e Criteria for identifying features might be drawn from the investigation. For instance, for the query on whether inactive oil wells in Texas and New Mexico were misclassified and could be soon abandoned, Aldern used state agency definitions of \"orphaned\" and \"inactive\" to label data. This intel was gleaned by Naveena Sadasivam and Christopher Collins, reporters on the oil and gas beat.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e3. Test the model to avoid overfitting or bias.\u003c/strong\u003e Models should make generalised accurate predictions. One trick to perfecting a model's performance is to divide the training dataset in half. Use the first half to train the model and the second to evaluate the accuracy trained model. Tweak the model based on the results of the test run on the second labelled dataset.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e4. Analyse the unlabeled data.\u003c/strong\u003e This step will leverage the trained data to provide an answer to the question you are asking of the remaining data: Which inactive oil wells could be misclassified as orphaned? Which files are spam? Which device reports have been misclassified as not causing harm? The methodology often relies on processes derived from statistical modellings such as linear regression, decision trees, logical regression, or clustering. It is written in programming languages such as R, Python or Julia.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e5. Corroborate results.\u003c/strong\u003e Aldern does this by \"trying to prove myself wrong.\" To check the machine learning results, data journalists interviewed for this piece will ask data scientists affiliated with universities to independently review the results. Best practice also includes writing a methods article (\u003ca href=\"https://grist.org/energy/scale-of-texas-new-mexico-abandoned-oil-wells/\"\u003eas Aldern did here\u003c/a\u003e), along with sharing links to \u003ca href=\"https://github.com/clayton-aldern/abandoned-wells\"\u003eGitHub repositories\u003c/a\u003e. Finally, boots-on-the-ground reporting will substantiate results.\u003c/p\u003e\n\n                                                                     \n                            \u003cp\u003eAbove shows a flowchart depicting how data journalists can label data to create learning instructions for machines so they can make useful predictions about unlabeled data. Source: Monika Sengul-Jones.\u003c/p\u003e\n\n                                                                                                 \u003ch3\u003eKey words in machine learning\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e:LABEL.\u003c/strong\u003e The label is the thing that will be predicted later, the dependent variable, the y variable in linear regression. A label could be a noun or an event. Spam. Spy Plane. Orphaned. Dead.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:FEATURES.\u003c/strong\u003e The features are the special things in the labelled item that will be used to define future undefined labelled items; otherwise known as independent variables. For instance, a feature might be pointy ears. A style of email address. Turn direction. Ownership status. Smoking habits.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e:CODE.\u003c/strong\u003e The algorithm used to analyse the data. Often, a version of a tried-and-true statistical model such as linear regression, decision tree, logical regression, or clustering but written in programming languages such as R, Python or Julia.\u003c/p\u003e\n\n                                                                     \n                            \n                                                                                                                                 \u003cp\u003eMonika Sengul-Jones, PhD, is a researcher, writer and expert on digital cultures and media industries. She lives in Seattle, Washington, USA. \u003ca href=\"https://twitter.com/monikajones\"\u003e@monikajones\u003c/a\u003e, \u003ca href=\"https://monikasjones.com\"\u003ewww.monikasjones.com\u003c/a\u003e\u003c/p\u003e\n\n                                                                                                                              \n                            \u003cp\u003eThanks to \u003ca href=\"https://carolinesinders.com/\"\u003eCaroline Sinders\u003c/a\u003e, a machine learning consultant, for being interviewed for background research for this piece.\u003c/p\u003e\n\n                                              \n                ","contentSnippet":"Oodles. Troves. Tsunamis. With data increasingly stored in extraordinary volume, investigative journalists can and have been piloting extraordinary analysis techniques to make sense of these enormous datasets--and, in doing so, hold corporations and governments accountable.\nThey’ve been doing this with machine learning, which is a subset of artificial intelligence that deepens data-driven reporting. It’s a technique that’s not just useful in an age of big data--but a must. \nThe unwritten rule about when to use machine learning in reporting is pretty simple. When the humans involved cannot reasonably analyse data themselves--we’re talking hundreds of thousands of lines on a spreadsheet--it’s time to bring in the machines.\nReporters, editors, software engineers, academics working together--that’s where the magic happens.\nWhat is machine learning?\nFor journalists just getting started, it might be comforting to know that machine learning shares many similarities with statistics. It’s also worth noting that the semantics are a point of contention. \n“Reasonable people will disagree on what to call what we’re doing now,” said Clayton Aldern, senior data reporter at Grist who recently co-reported the award-winning series Waves of Abandonment which used machine learning to identify misclassified oil wells in Texas and New Mexico.\nIndeed, a running joke is that “AI sells”--another data journalist referenced this image to me to make that point.\nThe sentiment isn’t unfounded. Meredith Broussard, professor, journalist and author of Artificial Unintelligence: How Computers Misunderstand the World, said in an interview with the Los Angeles Times that “AI” took hold as a catchy name for what was otherwise known as structured machine learning or statistical modelling, in order to expand commercial interest. But there are differences.\n“For one, we’re not using pen and paper,” said Aldern, who has masters degrees in neuroscience and public policy from the University of Oxford. “We have the computational power to put statistical theories to work.”\nMeredith Broussard is a professor and journalist who authored Artificial Unintelligence: How Computers Misunderstand the World.\nThat distinction is crucial, argues Meredith Whittaker, the Minderoo Research Professor at New York University and co-founder and director of the AI Now Institute. \nSupervised machine learning has become “shockingly effective” at predictive pattern recognition when trained using significant computational power and massive amounts of quality, human-labelled data. “But it is not the algorithm that was a breakthrough: it was what the algorithm could do when matched with large-scale data and computational resources,” Whittaker said.\nThe AI Now Institute at New York University aims to produce interdisciplinary research and public engagement to help ensure that AI systems are accountable to the communities and contexts in which they’re applied.\nScaling hardly means that humans aren’t involved. On the contrary, the effectiveness of machine learning in general, and for journalism, depends not only on access to quality, labelled data and computational resources, but the skills and infrastructural capacities of the people bringing these pieces together. In other words, newsrooms leveraging machine learning for reporting have journalists in the loop every step of the way.\n“[Machine learning] has a big human component […] it isn’t magic, it takes considerable time and resources,” said Emilia Díaz-Struck, research editor at International Consortium of Investigative Journalists (ICIJ), which has used machine learning in investigations for more than five years. “Reporters, editors, software engineers, academics working together--that’s where the magic happens.\"\nWhen is machine learning the right tool for the story?\nDesigning and running a machine learning programme is a big task--and there are numerous free or reasonably priced training programmes available for journalists and newsrooms to sharpen their skill sets--we describe the process and training options at the end of this article. But how does machine learning fit into the reporting process? Here are a few of the ways.\nManaging overload: Clustering to find leads\nWhen the International Consortium of Investigative Journalists, a nonprofit newsroom and network of journalists centred in Washington, D.C., obtained the files that would make up Pandora Papers--like the other exposés they’d reported including the Panama Papers, Paradise Papers--initially the sheer amount of information was mind-blowing.\n“Reporters were overwhelmed,” said Díaz-Struck. Before they could tell stories, they needed to know what was there, and what they didn’t need. To accomplish this, the ICIJ reporters used machine learning to sort and cluster, among other methods. “First, it worked like a spam filter,” said Díaz-Struck, referencing a popular machine learning application, which sometimes uses Bayes’ theorem to determine the probability that an email is either spam or not spam. The task sounds simple but wasn’t easy.\nICIJ used machine learning to help conduct the largest investigation in journalism history, the Pandora Papers.\n“[Miguel Fiandor called it] a sumo fight. Big data on one side, and on the other, all of us, the journalists, reporters, software developers, and editors,” Díaz-Struck said.  \nEventually, machine learning helped ICIJ cull data into more manageable groupings and together with ICIJ technologies as Datashare and other data analysis approaches, the team handled the big data. In parallel, more than 600 reporters from around the world took on the herculean effort of connecting the dots between reports of tax evasions and dubious financial dealings by hundreds of world leaders and billionaires.\nPointing fingers: Naming past misclassifications\nAnother popular use of machine learning is to name misclassifications. This was the tact taken in 2015, when Ben Poston, Joel Rubin and Anthony Pesce used machine learning for The Los Angeles Times to determine that The Los Angeles Police Department misclassified approximately 14,000 serious assaults as minor offences over an eight-year period. The misclassification made the city’s crime levels appear lower than accurate.\nAs far back as 2015, The Los Angeles Times used machine learning to show how the city's police department underestimated the city's crime levels by misclassifying thousands of assaults as minor offences.\nSimilarly, BuzzFeed News’ investigation of secret surveillance aircraft to hunt drug cartels in Mexico, by reporters Peter Aldhous and Karla Zabludovsky, was a question of classification. The effort, which Aldhous documented in a separate BuzzFeed article and on GitHub, used a random forest algorithm, a well-known statistical model for classification, to identify potential surveillance aircraft.\nBuzzFeed News trained a computer to find secret surveillance aircraft by letting a machine-learning algorithm sift for planes with flight patterns that resembled those operated by the FBI and the Department of Homeland Security.\nAnd misclassification was vital in the ICIJ’s Implant Files. This expansive investigation found that medical devices implanted into people’s bodies--such as vaginal netting, copper coil birth control, breast implants, heart monitors, hip replacements, and so on--were linked to more than 83,000 patient deaths and nearly 2 million injuries. Of patients who died, 2,100 people, or 23% of these deaths, were not reported as deaths but more vaguely classified as “device malfunctions or injuries.”\nChecking the wrong box has grave consequences, including misleading health authorities about when devices are linked to deaths and preventing the regulators from knowing a product merits further review--to the detriment of future patients. Díaz-Struck explained it took her team months to design and fact-check machine learning for this research. In the methodology article, published in 2018, she explains that text mining, clustering, and classification algorithms were all involved.\nThey went on to use machine learning to make a second classification, to identify patient gender, an unknown category that was not released by the patient files made available by the Federal Drug Administration in the United States. Many of those who had died or were harmed by implants were women, but not always from “women devices” such as breast implants.\nSometimes applications of machine learning come out of informal conversations.\nWhat were the numbers? Partnering with researchers at Stanford University, Díaz-Struck’s team painstakingly trained a machine to identify the gender of patients who had been harmed, or died, from an implanted medical device using the presence of pronouns or mention of gendered body parts in the notes section of the reports. \nAfter six months of effort, the team of nearly a dozen was able to identify the sex of 23% of the patients, of which 67% were women and 33% were men. A key limitation was the quality of the data, said Díaz-Struck. Nevertheless, the effects of this reporting are not only greater transparency but reforms.\nBy any other name? Predicting misclassifications\nSometimes applications of machine learning come out of informal conversations. That’s what happened with the Grist and Texas Observer story that predicts the number of unused oil and gas wells in the Permian Basin that will likely be abandoned in coming years. It will cost taxpayers a billion dollars. The story began with no talk of predictions, rather, it was an informal chat between Aldern and fellow Grist journalist Naveena Sadasivam.\n“She’s been on the oil beat for ages and when the COVID-19 pandemic hit, the price of oil dropped. It even went briefly negative. When that happens, some of the mom-and-pop companies hit hard times. Would any go bankrupt, she wondered? And what would happen to the wells?” Aldern said. Sadasivam joined Texas Observer reporter Christopher Collins to find out.\nLooking over data Sadasivam collected from public records requests, she and Aldern brainstormed “what we could say,” he recalled. They spent time organising it into a structured database, still unsure if there was a story. The dataset features included the production history of all the wells in Texas, plus macroeconomic indicators, employment, geotags, depth, drilling history for decades, and cost of oil over time.\nA collaborative Grist and Texas Observer story is pictured above.\n“At one point we asked, could we use this to figure out the future? This was a classification problem: which wells might be abandoned in the next couple years,” Aldern said. “And it’s a perfect question for machine learning.”\nThe results were damning. They predict 13,000 wells would be reclassified from inactive to abandoned in the next four years, costing taxpayers nearly one billion dollars--not to mention the environmental effects of abandonment. Sadasivam and Collin’s on-the-ground reporting corroborated these findings, based on interviews with experts and ranchers who worried, “no one is coming.”\nAldern documented the methodology in an article and shared the data and code in a GitHub file. He also was featured in the Conversations with Data podcast earlier this year.\nA screenshot from the story's Github file.\nHolding technological black boxes accountable with machine learning\nA subversive use of machine learning is holding privatised machine learning accountable. As the commercial rollout of AI has taken hold in the past decade--which has implications for newsrooms as well, which we will document in the second piece in this series--tech companies remain tightlipped about their processes, refusing to allow independent researchers to assess structured machine learning. \nMeanwhile, algorithmic predictions have been criticised for reproducing inequalities as Virginia Eubanks, a political science associate professor at the University of Albany, argues in her book \"Automating Inequality\"; or incentivising--and bankrolling--disinformation campaigns, as Karen Cho reports.\nFor data journalists who are new to machine learning, it’s possible to follow along the work of others to learn.\nThe Markup, led by Julia Angwin, is a nonprofit newsroom focused exclusively on “watchdog” reporting about Big Tech. Like other newsrooms featured in this story, The Markup leverages machine learning and other data-driven methodologies to reverse engineer the algorithms or identify misclassifications and publish a “show your work” article and release the data and code. \nMaddy Varner, an investigative journalist at The Markup said in an email that they use machine learning for investigations, including a random forest model in their work on Amazon’s treatment of its own brands, which was also described in a letter from Angwin, a story that took a year to break.\nAbove is a screenshot from The Markup homepage and its latest investigation examining Amazon's treatment of its own brands.\nTransparency builds trust. “It is very important to not just to say what you know but explain why you know it,” said Aldhous, who explained that transparency is a cornerstone value at Buzzfeed News. “The greater the ability to see under the hood of the methods, the better. It is like, this is how it works. This is why we have that number. This is why we think that’s a spy plane.”\nNo need to reinvent the robot\nIf getting started sounds daunting, one of the benefits of data science is the open-source community, said Aldern. Data journalists share code and training data on GitHub, where other data journalists or data scientists can take a look. \nDon’t be afraid to copy-paste. Borrow tried and true algorithms for logical regressions or decision trees. For data journalists who are new to machine learning, it’s possible to follow along the work of others to learn. \nBut reporting won’t be fast. Lucia Walinchus, executive director of the non-profit newsroom Eye on Ohio and a Pulitzer Center grantee, has spent more than six months using machine learning to analyse public records on housing repossession in Ohio. The project seeks to understand, mathematically, what makes land banks repossess some homes that are behind on taxes, but not others.\nIt's an open secret in any data story that the majority of the work is getting the data into order\n“It’s the perfect problem for software,” she said. Though machine learning is only part of the story and doesn’t replace investigative on-the-ground research. Her inaugural machine-learning investigation is slated for publication in the coming weeks.\nResource-strapped newsrooms can consider partnerships with academics or companies. The ICIJ has partnered with Stanford University and independent companies to address particularly gnarly data problems while maintaining journalistic independence--crucial when dealing with sensitive materials for a big story that hasn’t yet been broken. \nThe ICIJ doesn’t outsource the work of training data to ensure accuracy, though they did use a machine learning tool called Snorkel to help classify text and images. Outsourcing the human work of labelling to platforms such as Amazon’s Mechanical Turk, which relies on humans who are paid pennies, has raised ethical concerns.\nData journalists can also be mindful of criticism about the costs of partnerships with tech companies, as Whittaker writes. \nWhen independent journalists or academics need tech companies to access the computational power or intellectual resources to conduct research, those companies get to have the final say on decisions about what work to do, to promote, or discuss. “In the era of big data, journalists are not going to disappear, they are more essential than ever,” said Díaz-Struck.\nResources to master machine learning\nTo ramp up skills, there are free training programmes available. At the Associated Press, Aimee Rinehart is leading a new effort to expand local news organisations understanding and use of AI tools and technologies, funded with $750,000 from the Knight Foundation’s AI effort. News leaders in U.S. newsrooms can take a survey to inform the curriculum of an online course designed by AP; the survey closes in early December 2021. \nAfter running the course, AP will partner with five newsrooms to identify opportunities for AI and implement those strategies. This initiative follows on the heels of the London School of Economics Journalism AI project funded by Google News Initiative, which also offered a free course on AI for journalists.\nJournalists can sign up to data journalism bootcamps run by Investigative Reporters and Editors.\nInvestigative Reporters and Editors run data journalism bootcamps to teach hands-on technical skills to turn data into accurate, interesting stories. These trainings are not free, but prices vary based on the size of the newsroom, with scholarships available, as well as discounts for students and freelancers. Programmes support journalists to sharpen basic to advanced skills in spreadsheets, data visualisation and mapping, SQL, and coding in R and Python. Journalists should be members of IRE to enrol.\nData journalists can bootstrap their own training program by learning from and participating in machine learning competitions based on over 50,000 datasets, run by Kaggle. While not specifically designed for journalists, the competitions can be valuable and come with three-figure prizes (in U.S. dollars). A Google account is required.\nHow it works: Machine learning in a nutshell\nLet's run through the machine learning process. The basic tasks include the following:\n1. Assemble data. \"It's an open secret in any data story that the majority of the work is getting the data into order,\" said Aldern. Data can be public, garnered from public records requests, scraped, or shared from an external source. Consider the questions you'd like to use the data to answer.\n2. Identify labels and features of some data to build a statistical model. Criteria for identifying features might be drawn from the investigation. For instance, for the query on whether inactive oil wells in Texas and New Mexico were misclassified and could be soon abandoned, Aldern used state agency definitions of \"orphaned\" and \"inactive\" to label data. This intel was gleaned by Naveena Sadasivam and Christopher Collins, reporters on the oil and gas beat.\n3. Test the model to avoid overfitting or bias. Models should make generalised accurate predictions. One trick to perfecting a model's performance is to divide the training dataset in half. Use the first half to train the model and the second to evaluate the accuracy trained model. Tweak the model based on the results of the test run on the second labelled dataset.\n4. Analyse the unlabeled data. This step will leverage the trained data to provide an answer to the question you are asking of the remaining data: Which inactive oil wells could be misclassified as orphaned? Which files are spam? Which device reports have been misclassified as not causing harm? The methodology often relies on processes derived from statistical modellings such as linear regression, decision trees, logical regression, or clustering. It is written in programming languages such as R, Python or Julia.\n5. Corroborate results. Aldern does this by \"trying to prove myself wrong.\" To check the machine learning results, data journalists interviewed for this piece will ask data scientists affiliated with universities to independently review the results. Best practice also includes writing a methods article (as Aldern did here), along with sharing links to GitHub repositories. Finally, boots-on-the-ground reporting will substantiate results.\nAbove shows a flowchart depicting how data journalists can label data to create learning instructions for machines so they can make useful predictions about unlabeled data. Source: Monika Sengul-Jones.\nKey words in machine learning\n:LABEL. The label is the thing that will be predicted later, the dependent variable, the y variable in linear regression. A label could be a noun or an event. Spam. Spy Plane. Orphaned. Dead.\n:FEATURES. The features are the special things in the labelled item that will be used to define future undefined labelled items; otherwise known as independent variables. For instance, a feature might be pointy ears. A style of email address. Turn direction. Ownership status. Smoking habits.\n:CODE. The algorithm used to analyse the data. Often, a version of a tried-and-true statistical model such as linear regression, decision tree, logical regression, or clustering but written in programming languages such as R, Python or Julia.\nMonika Sengul-Jones, PhD, is a researcher, writer and expert on digital cultures and media industries. She lives in Seattle, Washington, USA. @monikajones, www.monikasjones.com\nThanks to Caroline Sinders, a machine learning consultant, for being interviewed for background research for this piece.","guid":"https://datajournalism.com/read/longreads/machine-learning-investigative-journalism","isoDate":"2021-12-01T06:00:00.000Z","blogTitle":"DataJournalism.com"}},"__N_SSG":true},"page":"/[...slug]","query":{"slug":["bring-in-the-machines-ai-powered-investigative-journalism"]},"buildId":"g_JtxhWbqiyn-x4UYiLa0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>