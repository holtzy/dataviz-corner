<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/dd8d3b5be9662933.css" as="style"/><link rel="stylesheet" href="/_next/static/css/dd8d3b5be9662933.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-59c5c889f52620d6.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-f11614d8aa7ee555.js" defer=""></script><script src="/_next/static/chunks/pages/_app-891652dd44e1e4e1.js" defer=""></script><script src="/_next/static/chunks/996-eeb5175dbd5dba8f.js" defer=""></script><script src="/_next/static/chunks/36-94b5e24e03efc6db.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...slug%5D-af748dcc13a25fcb.js" defer=""></script><script src="/_next/static/sFP8FhENNxqFJqEgxMEWp/_buildManifest.js" defer=""></script><script src="/_next/static/sFP8FhENNxqFJqEgxMEWp/_ssgManifest.js" defer=""></script></head><body><div id="__next"></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"creator":"Brant Houston","title":"The history of data journalism","link":"https://datajournalism.com/read/longreads/the-history-of-data-journalism","pubDate":"Mon, 13 Dec 2021 06:30:00 +0100","author":"Brant Houston","content":"\n                                                                        \u003cp\u003eIt all started with trying to predict the outcome of a US presidential election.\u003c/p\u003e\n\u003cp\u003eMany practitioners date the beginning of computer-assisted reporting and data journalism to 1952 when the CBS network in the United States tried to use experts with a mainframe computer to predict the outcome of the presidential election. \u003c/p\u003e\n\u003cp\u003eThat’s a bit of a stretch, or perhaps it was a false beginning because they never used the data for the story. It really wasn’t until 1967 that data analysis started to catch on.\u003c/p\u003e\n\u003cp\u003eIn that year, Philip Meyer at \u003cstrong\u003eThe Detroit Free Press\u003c/strong\u003e used a mainframe computer (known as big iron) to analyse a survey of Detroit residents for the purpose of understanding and explaining the serious riots that erupted in the city that summer. Decades later, \u003cstrong\u003eThe Guardian\u003c/strong\u003e in the United Kingdom used some of the same approaches to look at racial riots there and cited Meyer’s work.\u003c/p\u003e\n\u003cp\u003eMeyer went on to work in the 1970s with \u003cstrong\u003ePhiladelphia Inquirer\u003c/strong\u003e reporters \u003cstrong\u003eDonald Barlett\u003c/strong\u003e and \u003cstrong\u003eJames Steele\u003c/strong\u003e to analyse sentencing patterns in the local court system, and with \u003cstrong\u003eRich Morin\u003c/strong\u003e at \u003cstrong\u003eThe Miami Herald\u003c/strong\u003e to analyse property assessment records. \u003c/p\u003e\n\u003cp\u003eMeyer also wrote a book called \u003ca href=\"https://books.google.hu/books?id=uUzT0M_lPbYC\u0026amp;printsec=frontcover#v=onepage\u0026amp;q\u0026amp;f=false\"\u003ePrecision Journalism\u003c/a\u003e that explained and advocated using database analysis and social research methods in reporting. Revisions of the book, now called \u003cstrong\u003e\u003ca href=\"https://www.amazon.co.uk/New-Precision-Journalism-Midland-Book/dp/0253206642\"\u003eNew Precision Journalism\u003c/a\u003e\u003c/strong\u003e, have been published since then.\u003c/p\u003e\n\n                                                                     \n                            \n                                                                      \n                            \u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eStill, only a few journalists used these techniques until the mid-1980s, when \u003cstrong\u003eElliot Jaspin\u003c/strong\u003e in the U.S. received recognition at \u003cstrong\u003eThe Providence Journal Bulletin\u003c/strong\u003e for analysing databases for stories, including those on dangerous school bus drivers and a political scandal involving home loans. \u003c/p\u003e\n\u003cp\u003eJaspin, who had won a Pulitzer Prize for traditional reporting on labour union corruption, also had taken a fellowship at Columbia University to learn how to use data. This was the same university where a journalist and professor \u003cstrong\u003eSteve Ross\u003c/strong\u003e had been teaching data analysis techniques for years. By the late 1980s, about 50 other journalists across the U.S., often consulting with Meyer, Jaspin, or \u003ca href=\"https://datajournalism.com/contributors/steve_doig\"\u003eSteve Doig\u003c/a\u003e of the \u003cstrong\u003eMiami Herald\u003c/strong\u003e, had begun using data analysis for their stories.\u003c/p\u003e\n\n                                                                                                 \u003cblockquote\u003e\u003cp\u003eThe use of data by journalists has vastly expanded since 2015.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003cp\u003eAiding the efforts of the data journalists of the 1980s were improved personal computers and a much-needed software—\u003cstrong\u003eNine Track Express\u003c/strong\u003e—that Jaspin and journalist-programmer \u003cstrong\u003eDaniel Woods\u003c/strong\u003e wrote to make it easier to transfer computer tapes (that contained nine “tracks” of data) to personal computers using a portable tape drive. \u003c/p\u003e\n\u003cp\u003eThis was a remarkable breakthrough because it allowed journalists to circumvent the internal bureaucracies and delays involved in using mainframes at newspapers and universities and instead do their work at their desks.\u003c/p\u003e\n\u003cp\u003eIn 1989, U.S. journalism recognised the value of computer-assisted reporting when it gave a Pulitzer to \u003cstrong\u003eThe Atlanta Journal-Constitution\u003c/strong\u003e for stories on racial disparities in home loans. The project was one of the first collaborations on data stories that involved an investigative reporter, a data reporter and college professors.\u003c/p\u003e\n\u003cp\u003eDuring the same year, Jaspin established at the \u003cstrong\u003eMissouri School of Journalism\u003c/strong\u003e what is now known as the \u003ca href=\"https://www.ire.org/about-ire/\"\u003eNational Institute for Computer-Assisted Reporting (NICAR)\u003c/a\u003e. Then, in 1990, \u003cstrong\u003eIndiana University\u003c/strong\u003e professor \u003cstrong\u003eJames Brown\u003c/strong\u003e held the first computer-assisted reporting conference in Indianapolis, Indiana and continued them for several years.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eIn the 1990s through early in the 21st Century, the use of computer-assisted reporting blossomed, primarily due to the seminars conducted at Missouri and worldwide by \u003ca href=\"http://www.ire.org/\"\u003eInvestigative Reporters and Editors (IRE)\u003c/a\u003e and NICAR. \u003c/p\u003e\n\u003cp\u003eIRE held its first computer-assisted reporting conference in 1993 and after that, the conferences were a project of IRE and NICAR. The growth of computer-assisted reporting was aided by the publication of my book in 1996, the first on doing CAR, \u003ca href=\"https://www.amazon.co.uk/Computer-Assisted-Reporting-Practical-Brant-Houston/dp/1138855030\"\u003e\"Computer-Assisted Reporting: A Practical Guide,”\u003c/a\u003e now in its 5th edition. \u003c/p\u003e\n\u003cp\u003eI wrote the book so that it could be used as a textbook for university classes, but also for the lone and lonely practitioner in newsrooms that did realise the power of data and thought having a “nerd” in the corner of the newsroom sufficed for what was an ongoing revolution in journalism.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003cp\u003e\u0026nbsp; \u003c/p\u003e\n\u003cp\u003eAfter NICAR was created in 1994, training director \u003cstrong\u003eJennifer LaFleur\u003c/strong\u003e and I initiated an ambitious on-the-road programme that eventually included up to 50 seminars a year with the help of colleagues across the country who volunteered their expertise and their time. \u003c/p\u003e\n\u003cp\u003eThe creation of the on-the-road training was bolstered by the advent of the World Wide Web, which helped journalists immensely in their understanding of, and comfort with, the digital world and data. By 1996 word of the U.S. successes had reached other countries, and foreign journalists began attending the “boot camps” (intense, week-long seminars) at NICAR. \u003c/p\u003e\n\u003cp\u003eIn addition, IRE, with the support of the \u003cstrong\u003eMcCormick Foundation\u003c/strong\u003e, had set up a programme in Mexico City that did data training in Latin America, which was led by the programme’s director \u003cstrong\u003eLise Olsen\u003c/strong\u003e, who travelled and trained throughout the continent of South America.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003ch3\u003eGoing global\u003c/h3\u003e\n\u003cp\u003eWhile journalists outside the U.S. at first doubted they could obtain data in their own countries in the 1990s, the training showed them how international or U.S. data could be used initially for stories in their countries, how they could build their own datasets, and how they could find data collected and stored by their governments.\u003c/p\u003e\n\u003cp\u003eAs a result of the extensive training efforts, journalists had produced stories by 1999 involving data analysis in an array of countries, including Finland, Sweden, New Zealand, Venezuela, Argentina, the Netherlands, Norway, Brazil, Mexico, Russia, Bosnia, and Canada.\u003c/p\u003e\n\u003cp\u003eMeanwhile, in London in 1997, journalism professor \u003cstrong\u003eMilverton Wallace\u003c/strong\u003e began holding an annual conference called \u003cstrong\u003eNetMedia\u003c/strong\u003e that offered sessions on the Internet and classes in computer-assisted reporting led by NICAR and Danish journalists. \u003c/p\u003e\n\u003cp\u003eThe classes covered the basic uses of the Internet, spreadsheets, and database managers, and they were well-attended by journalists from the UK, other European countries, and Africa.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eIn Denmark, journalists \u003cstrong\u003eNils Mulvad\u003c/strong\u003e and \u003cstrong\u003eFlemming Svith\u003c/strong\u003e, who had gone to a NICAR boot camp in Missouri in 1996, organised seminars with NICAR in 1997 and 1998 in Denmark. \u003c/p\u003e\n\u003cp\u003eThey also wrote a Danish handbook on computer-assisted reporting, created the Danish International Center for Analytical Reporting (DICAR) in 1998 with \u003ca href=\"https://www.kaasogmulvad.dk/en/\"\u003eTommy Kaas\u003c/a\u003e as president. This led to them also co-organising the first Global Investigative Journalism Conference with IRE in 2001.\u003c/p\u003e\n\u003cp\u003eCAR also became a staple of conferences in Sweden, Norway, Finland, and the Netherlands, with Helena Bengtsson from Sweden and John Bones from Norway. \u003c/p\u003e\n\u003cp\u003eIn Brazil, the investigative journalism association, \u003cstrong\u003eAbraji\u003c/strong\u003e formed in 2002 with training in data journalism as part of its core mission. Two key leaders in data journalism training by Abraji in Brazil were \u003cstrong\u003eJose Roberto de Toledo\u003c/strong\u003e and \u003cstrong\u003eMarcelo Soares\u003c/strong\u003e.\u003c/p\u003e\n\n                                                                      \n                            \u003ch3\u003eData journalism comes of age\u003c/h3\u003e\n\u003cp\u003eThe early years of the 21st century also saw the Global Investigative Journalism Network begin to play a crucial part in the movement, starting with its first conference in 2001 in Copenhagen that offered a strong computer-assisted reporting track and hands-on training in conjunction with sessions on traditional investigative reporting.\u003c/p\u003e\n\u003cp\u003eThrough the global investigative conferences, the use of data quickly spread across Eastern Europe. In Eastern Europe, \u003cstrong\u003eDrew Sullivan\u003c/strong\u003e, one of the original NICAR trainers and data administrators, formed the \u003ca href=\"https://www.occrp.org/en\"\u003eOrganized Crime and Corruption Reporting Project\u003c/a\u003e, which has become a leader in data journalism.\u003c/p\u003e\n\n                                                                                                 \u003cblockquote\u003e\u003cp\u003eBy 2009, the increasing number of computer programmers and coders in journalism resulted in creation of Hacks/Hackers.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003cp\u003eHe and Romanian journalist Paul Radu were strong proponents and organisers of data training sessions and projects. Seminars also were given initially in China through the \u003cstrong\u003eUniversity of Missouri\u003c/strong\u003e and in India through the \u003cstrong\u003eWorld Press Institute\u003c/strong\u003e, led by \u003cstrong\u003eJohn Ullmann\u003c/strong\u003e, who had been IRE’s first full-time executive director. \u003c/p\u003e\n\u003cp\u003eUllmann also oversaw training in Latin America, recruiting me and other NICAR trainers to assist him. \u003c/p\u003e\n\u003cp\u003eDuring the same period Doig, a pioneer in CAR and later the Knight Chair in Computer-Assisted Reporting at \u003cstrong\u003eArizona State University\u003c/strong\u003e, travelled internationally to teach CAR, as did additional NICAR training directors — \u003cstrong\u003eSarah Cohen, Andy Lehren, Jo Craven McGinty, Tom McGinty, Ron Nixon, Neil Reisner, and Sarah Cohen\u003c/strong\u003e -- all practising journalists who went onto work at The New York Times, The Wall Street Journal, The Washington Post, and the Miami Herald.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003ch3\u003eVisualisation of data increases\u003c/h3\u003e\n\u003cp\u003eVisualisation of data in charts and maps had been on the rise for some time, inspired by a map by Doig in 1992 for the \u003cstrong\u003eMiami Herald\u003c/strong\u003e. Showing the deep value of data visualisation for analysis, Doig created a map of hurricane wind speeds and building damage in the Miami area after Hurricane Andrew. \u003c/p\u003e\n\u003cp\u003eThe map revealed a pattern of severe property damage where wind speeds had been low. Following up on that revelation, reporters found that shoddy construction and sloppy building inspections had led to the damage.\u003c/p\u003e\n\u003cp\u003eIn 2005, the visualisation of data for news stories got another boost when U.S. programmer \u003cstrong\u003eAdrian Holovaty\u003c/strong\u003e created a \u003ca href=\"http://www.holovaty.com/writing/chicagocrime.org-tribute/\"\u003eGoogle mash-up of Chicago crime data\u003c/a\u003e. The project spurred more interest in journalism among computer programmers and in mapping. \u003c/p\u003e\n\u003cp\u003eHolovaty and his team of coders then created the now-defunct \u003cstrong\u003eEvery Block\u003c/strong\u003e in 2007, which used more local data for online maps in the U.S., but the project later ran into criticism for not checking the accuracy of government data more thoroughly.\u003c/p\u003e\n\u003cp\u003eIn 2007, the open data movement in the U.S. began in earnest, spawning other such efforts worldwide. The movement increased accessibility to government data internationally, although the need remained to have freedom of information laws to get data not released by the governments.\u003c/p\u003e\n\n                                                                                                 \u003cblockquote\u003e\u003cp\u003eThe use of data by journalists has now become so prevalent it is easier to keep track of the progress.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003cp\u003eBy 2009, the increasing number of computer programmers and coders in journalism resulted in creation of \u003ca href=\"https://www.hackshackers.com/\"\u003eHacks/Hackers\u003c/a\u003e, which would encourage more sharing between journalists and coders and ease some of the culture clash between the two groups.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAron Pilhofer\u003c/strong\u003e, then of The New York Times and now at \u003cstrong\u003eTemple University\u003c/strong\u003e, and \u003cstrong\u003eRich Gordon\u003c/strong\u003e from \u003cstrong\u003eNorthwestern University’s Medill School of Journalism\u003c/strong\u003e, had pushed for creation of “a network of people interested in Web/digital application development and technology innovation supporting the mission and goals of journalism.” \u003c/p\u003e\n\u003cp\u003eAt the same time in Silicon Valley, \u003cstrong\u003eBurt Herman\u003c/strong\u003e brought journalists and technologists together. The three then joined to create \u003cstrong\u003e“Hacks/Hackers.”\u003c/strong\u003e The result has been an increasing technological sophistication within newsrooms that has increased the ability to scrape data from Web sites and make it more manageable, visual, and interactive.\u003c/p\u003e\n\u003cp\u003eAnother outcome of the journalist-programmer mashup was the new respect among coders for knowing how flawed databases are, and for ensuring the integrity of the data.\u003c/p\u003e\n\u003cp\u003eAs was well-said by \u003cstrong\u003eMarcos Vanetta\u003c/strong\u003e, a Mozilla OpenNews fellow who worked at \u003cstrong\u003eThe Texas Tribune\u003c/strong\u003e: “Bugs are not optional… In software, we are used to making mistakes and correcting them later. We can always fix that later and in the worst case, we have a backup. In news, you can’t make mistakes -- there is a reputation to take care of. The editorial team is not as used to failure as developers are.”\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ch3\u003eMore breakthroughs\u003c/h3\u003e\n\u003cp\u003eThe years 2009, 2010, and 2011 also were breakthrough years for using data for journalism. In Canada in 2009, Fred Vallance-Jones and David McKie published \u003ca href=\"https://www.amazon.com/Computer-Assisted-Reporting-A-Comprehensive-Primer/dp/0195424573\"\u003e“Computer-Assisted Reporting: A Comprehensive Primer”\u003c/a\u003e with a special emphasis on CAR in Canada. \u003c/p\u003e\n\u003cp\u003eThis was also the year that journalist \u003ca href=\"https://datajournalism.com/contributors/simonrogers\"\u003eSimon Rogers\u003c/a\u003e launched \u003ca href=\"https://www.theguardian.com/news/datablog/2009/mar/10/blogpost1\"\u003eThe Guardian's data blog\u003c/a\u003e.  \u003c/p\u003e\n\u003cp\u003eThe \u003ca href=\"https://ejc.net/\"\u003eEuropean Journalism Centre\u003c/a\u003e began its data-driven journalism programme that has organised workshops throughout Europe. This led to the establishment of \u003cstrong\u003eDataJournalism.com\u003c/strong\u003e for online training courses and other resources. \u003c/p\u003e\n\u003cp\u003eJournalist \u003cstrong\u003e\u003ca href=\"https://datajournalism.com/contributors/paulbradshaw\"\u003ePaul Bradshaw\u003c/a\u003e\u003c/strong\u003e became recognised as a pioneer in data journalism in the United Kingdom. In 2009, Wikileaks released its \u003ca href=\"https://wikileaks.org/afg/\"\u003e\"Afghan War Diaries\"\u003c/a\u003e, composed of secret documents and then the \u003cstrong\u003eIraq War Diaries\u003c/strong\u003e, requiring journalists throughout the world to deal with enormous amounts of data in text.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eThis was followed in 2011 by The Guardian’s impressive series using data and social media to analyse city racial riots in the United Kingdom. Journalist and author Brigitte Alfter then founded the first \u003ca href=\"https://dataharvest.eu/\"\u003eDataharvest conference\u003c/a\u003e, which is now led by the \u003ca href=\"https://journalismarena.eu/\"\u003eArena for Journalism in Europe\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe same year work began in London on the first \u003ca href=\"https://datajournalism.com/read/handbook/one\"\u003eData Journalism Handbook\u003c/a\u003e (now in a \u003ca href=\"https://datajournalism.com/read/handbook/two\"\u003esecond edition\u003c/a\u003e and available in several languages) it was written by a consortium of contributors from around the world.\u003c/p\u003e\n\u003cp\u003eAlso in the United Kingdom, the \u003cstrong\u003eCentre for Investigative Reporting\u003c/strong\u003e, led by \u003cstrong\u003eGavin MacFadyen\u003c/strong\u003e, which teamed up in its early days with IRE to offer classes in data journalism during its summer school, ran a strong programme on its own with the assistance of CAR veteran trainer \u003cstrong\u003eDavid Donald\u003c/strong\u003e.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                      \n                            \u003ch3\u003eData journalism in the global south\u003c/h3\u003e\n\u003cp\u003eMeanwhile, at \u003cstrong\u003eWits University in South Africa\u003c/strong\u003e, \u003cstrong\u003eAnton Harber\u003c/strong\u003e and \u003cstrong\u003eMargaret Renn\u003c/strong\u003e substantially increased the data sessions at the annual \u003cstrong\u003ePower Reporting Conference\u003c/strong\u003e, now the \u003cstrong\u003eAfrican Investigative Journalism Conference\u003c/strong\u003e. \u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eCode For Africa\u003c/strong\u003e founder \u003cstrong\u003eJustin Arenstein\u003c/strong\u003e and his team also paved the way for data journalists on the continent. In 2012, he launched Africa's largest data journalism and civic tech lab covering stories involving, environment and climate change, women, gender and health/science. \u003c/p\u003e\n\u003cp\u003eIn Asia, journalists in countries including India, Malaysia, the Philippines, and South Korea began using digital tools, especially those for visualisation, and data stories for high impact stories and exchanging techniques and story ideas at GIJN’s biannual Asia conferences.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                                                 \u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003cp\u003eJournalists also began incorporating social media into their investigations more often. One striking story, using social network analysis, was done by journalists in South Korea, who uncovered an attempt by intelligence officers to undermine elections through social media propaganda. Inspiring data-led interactive pieces also came out of publications like South China Morning Post. \u003c/p\u003e\n\u003cp\u003eIn the Middle East, Egyptian data journalist \u003cstrong\u003eAmr Eleraqi\u003c/strong\u003e set up the Infotimes in 2012 followed by the \u003cstrong\u003eArab Data Journalists' Network\u003c/strong\u003e five years later. He began teaching the first Arabic-led data journalism training programme of its kind in the region. Meanwhile, \u003cstrong\u003eIJNET\u003c/strong\u003e and \u003cstrong\u003eArab Reporters for Investigative Journalism (ARIJ)\u003c/strong\u003e have continued to engage in offering training opportunities to Arab journalists in recent years.    \u003c/p\u003e\n\u003cp\u003eIn Latin America, \u003cstrong\u003eGiannina Segnini\u003c/strong\u003e, now at Columbia University, led a team of journalists and computer engineers at \u003cstrong\u003eLa Nación in Costa Rica\u003c/strong\u003e to produce stories by gathering, analysing, and visualising public databases.\u003c/p\u003e\n\u003cp\u003eMeanwhile in Brazil, \u003ca href=\"https://datajournalism.com/contributors/ncortezrj\"\u003eNatalia Mazotte\u003c/a\u003e from \u003cstrong\u003eOpen Knowledge Brasil\u003c/strong\u003e launched \u003cstrong\u003eEscola de Dados (School of Data Brazil chapter)\u003c/strong\u003e, in 2012 to train journalists with their data literacy programme. By 2015, Abraji had created online courses in data journalism.  A year later, Brazil's \u003cstrong\u003eCoda Festival\u003c/strong\u003e (Coda.Br) launched and grew to become the largest data journalism conference in Latin America. \u003c/p\u003e\n\u003cp\u003eAcross the global south, data journalist \u003cstrong\u003eEva Constantaras\u003c/strong\u003e began to develop training curricula for investigative and data journalism in high-risk environments with limited data access on behalf of Internews. Journalists have benefited from this data journalism training in a range of countries, including Afghanistan, India, Kenya, Kyrgyzstan and Myanmar.\u003c/p\u003e\n\n                                                                                                \u003cblockquote\u003e\u003cp\u003eBy 2020, the COVID-19 pandemic revealed the breadth and depth of the skills journalists had accumulated.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n                                                                     \n                            \u003cp\u003e\u0026nbsp;\u003c/p\u003e\n\u003ch3\u003eA revolution in journalism\u003c/h3\u003e\n\u003cp\u003eThe use of data by journalists and in the digital tools journalists use has vastly expanded since 2015. Journalists have probed deeper into the analysis of unstructured data -- text, video, and sound -- and woven those media into compelling investigative stories. \u003c/p\u003e\n\u003cp\u003eThey have more routinely managed gigabytes of data for stories and organised massive data leaks with agility and become more sophisticated in visualising data through maps, social network analysis or change over time in both newsgathering and presentation. \u003c/p\u003e\n\u003cp\u003eThey have conducted both traditional and innovative surveys to collect data to uncover social injustice. And the education and training -- and the syllabi and curricula at universities -- have become more focused and rigorous, thus producing new generations of data-savvy journalists. \u003c/p\u003e\n\u003cp\u003eThe result has been an ever-growing stream of data-driven stories by small and large newsrooms -- often in collaborations -- that provide not only context and depth to stories, but also real facts, tips, surprises and epiphanies for journalists and their audiences. \u003c/p\u003e\n\u003cp\u003eBy 2020, the COVID-19 pandemic revealed the breadth and depth of the skills journalists had accumulated and throughout the world journalists collected, analysed, and visualised pandemic data on a daily basis, often far exceeding what public health officials offered and, in fact, exposing the shortcomings of the data on which policy and practice were being decided.\u003c/p\u003e\n\n                                                                                                 \u003cp\u003e\u003cstrong\u003eThe use of data by journalists has now become so prevalent it is easier to keep track of the progress and new directions by major categories. Among them:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eThe collaborations of journalists, sometimes with universities, who use huge datasets, including leaks of data. The collaboration has become nearly a standard practice and the high-profile \u003cstrong\u003eInternational Consortium of Investigative Journalists\u003c/strong\u003e (ICIJ); the \u003cstrong\u003eBig Local News Project\u003c/strong\u003e in the U.S. or \u003cstrong\u003eConnectas\u003c/strong\u003e in Latin America are just a few examples of ongoing collaborations.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eThe achievements allowed by free software that breaks the income barriers to entry into the field. The software includes a variety of tools to scrape, analyse and/or visualise data and include Google tools, Tableau, Datawrapper and many others.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eThe exploration of using Artificial Intelligence or Machine Learning to discern patterns and outliers for further reporting such as Reuters’ project called \u003cstrong\u003eLynx Insights\u003c/strong\u003e, which uses an automation tool designed to help reporters accelerate the production of their existing stories or spot new ones.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eThe melding and analysis of satellite imagery, open-source video and photographs, social media, crowdsourcing and data for what are sometimes called visual or forensic investigations that are done by groups like Bellingcat.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003eSurveys through emails or mobile phones, such as the \u003cstrong\u003e\"Forced Out” project\u003c/strong\u003e that a mobile phone survey to create a database from interviewing thousands of displaced people across South Sudan.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n                                                                     \n                            \u003cp\u003eThese advances, however, are not replacing but augmenting the original uses of computers and data for journalism that began by applying social science methods and statistical and data analysis to government and business corruption, health and environmental stories, and societal issues.  \u003c/p\u003e\n\u003cp\u003eThe use of data has broadened over the years from counting instances of incidents and accidents in spreadsheets to using database managers to match apparently unrelated datasets to mapping data geographically and in social networks, to web scraping, to more efficient data cleaning, to better surveys, crowdsourcing and audience interaction, and to text mining with algorithms. \u003c/p\u003e\n\u003cp\u003eBut all of the work is still in the service of finding patterns, trends and outliers that lead to new knowledge and better news stories in the public interest. Over the decades, there also has been much discussion on what to call the use of data for high-quality journalism and various branding efforts to label it. \u003c/p\u003e\n\u003cp\u003eBut whether it is called “precision journalism,” “computer-assisted reporting,” “data journalism,” ‘data-driven journalism,” or “computational journalism,” the good news is that it is not only here to stay, but will continue to become more critical to revealing truths, holding the powerful accountable, and protecting those who otherwise would be exploited.\u003c/p\u003e\n\n                                                                      \n                            \n                                                                                                 \u003ch3\u003eFurther reading\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.co.uk/Precision-Journalism-Reporters-Introduction-Science/dp/0742510883\"\u003e\"New Precision Journalism,\" by Philip Meyer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.routledge.com/Data-for-Journalists-A-Practical-Guide-for-Computer-Assisted-Reporting/Houston/p/book/9780815370406\"\u003e\"Data for Journalists: A Practical Guide for Computer-Assisted Reporting\" by Brant Houston\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://datajournalism.com/read/handbook/two\"\u003e\"Data Journalism Handbook 2.0\"\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.amazon.com/Data-Literacy-David-Herzog/dp/1483333469\"\u003e\"Data Literacy,\" by David Herzog\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://journalism.columbia.edu/system/files/content/teaching_data_and_computational_journalism.pdf\"\u003e\"Teaching Data and Computational Journalism\" by Charles Berret and Cheryl Phillips\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\n                                                                                                                                \u003cp\u003eProfessor Brant Houston holds is the Knight Foundation Chair in Investigative and Enterprise Reporting at the University of Illinois. Houston teaches investigative and advanced reporting in the Department of Journalism, where he teaches investigative and data journalism. He also is editor of the online newsroom at Illinois, CU-CitizenAccess.org , which also serves as a lab for digital innovation and data journalism.\u003c/p\u003e\n\n                                                                                                      \n                ","contentSnippet":"It all started with trying to predict the outcome of a US presidential election.\nMany practitioners date the beginning of computer-assisted reporting and data journalism to 1952 when the CBS network in the United States tried to use experts with a mainframe computer to predict the outcome of the presidential election. \nThat’s a bit of a stretch, or perhaps it was a false beginning because they never used the data for the story. It really wasn’t until 1967 that data analysis started to catch on.\nIn that year, Philip Meyer at The Detroit Free Press used a mainframe computer (known as big iron) to analyse a survey of Detroit residents for the purpose of understanding and explaining the serious riots that erupted in the city that summer. Decades later, The Guardian in the United Kingdom used some of the same approaches to look at racial riots there and cited Meyer’s work.\nMeyer went on to work in the 1970s with Philadelphia Inquirer reporters Donald Barlett and James Steele to analyse sentencing patterns in the local court system, and with Rich Morin at The Miami Herald to analyse property assessment records. \nMeyer also wrote a book called Precision Journalism that explained and advocated using database analysis and social research methods in reporting. Revisions of the book, now called New Precision Journalism, have been published since then.\n \nStill, only a few journalists used these techniques until the mid-1980s, when Elliot Jaspin in the U.S. received recognition at The Providence Journal Bulletin for analysing databases for stories, including those on dangerous school bus drivers and a political scandal involving home loans. \nJaspin, who had won a Pulitzer Prize for traditional reporting on labour union corruption, also had taken a fellowship at Columbia University to learn how to use data. This was the same university where a journalist and professor Steve Ross had been teaching data analysis techniques for years. By the late 1980s, about 50 other journalists across the U.S., often consulting with Meyer, Jaspin, or Steve Doig of the Miami Herald, had begun using data analysis for their stories.\nThe use of data by journalists has vastly expanded since 2015.\nAiding the efforts of the data journalists of the 1980s were improved personal computers and a much-needed software—Nine Track Express—that Jaspin and journalist-programmer Daniel Woods wrote to make it easier to transfer computer tapes (that contained nine “tracks” of data) to personal computers using a portable tape drive. \nThis was a remarkable breakthrough because it allowed journalists to circumvent the internal bureaucracies and delays involved in using mainframes at newspapers and universities and instead do their work at their desks.\nIn 1989, U.S. journalism recognised the value of computer-assisted reporting when it gave a Pulitzer to The Atlanta Journal-Constitution for stories on racial disparities in home loans. The project was one of the first collaborations on data stories that involved an investigative reporter, a data reporter and college professors.\nDuring the same year, Jaspin established at the Missouri School of Journalism what is now known as the National Institute for Computer-Assisted Reporting (NICAR). Then, in 1990, Indiana University professor James Brown held the first computer-assisted reporting conference in Indianapolis, Indiana and continued them for several years.\n \nIn the 1990s through early in the 21st Century, the use of computer-assisted reporting blossomed, primarily due to the seminars conducted at Missouri and worldwide by Investigative Reporters and Editors (IRE) and NICAR. \nIRE held its first computer-assisted reporting conference in 1993 and after that, the conferences were a project of IRE and NICAR. The growth of computer-assisted reporting was aided by the publication of my book in 1996, the first on doing CAR, \"Computer-Assisted Reporting: A Practical Guide,” now in its 5th edition. \nI wrote the book so that it could be used as a textbook for university classes, but also for the lone and lonely practitioner in newsrooms that did realise the power of data and thought having a “nerd” in the corner of the newsroom sufficed for what was an ongoing revolution in journalism.\n  \nAfter NICAR was created in 1994, training director Jennifer LaFleur and I initiated an ambitious on-the-road programme that eventually included up to 50 seminars a year with the help of colleagues across the country who volunteered their expertise and their time. \nThe creation of the on-the-road training was bolstered by the advent of the World Wide Web, which helped journalists immensely in their understanding of, and comfort with, the digital world and data. By 1996 word of the U.S. successes had reached other countries, and foreign journalists began attending the “boot camps” (intense, week-long seminars) at NICAR. \nIn addition, IRE, with the support of the McCormick Foundation, had set up a programme in Mexico City that did data training in Latin America, which was led by the programme’s director Lise Olsen, who travelled and trained throughout the continent of South America.\nGoing global\nWhile journalists outside the U.S. at first doubted they could obtain data in their own countries in the 1990s, the training showed them how international or U.S. data could be used initially for stories in their countries, how they could build their own datasets, and how they could find data collected and stored by their governments.\nAs a result of the extensive training efforts, journalists had produced stories by 1999 involving data analysis in an array of countries, including Finland, Sweden, New Zealand, Venezuela, Argentina, the Netherlands, Norway, Brazil, Mexico, Russia, Bosnia, and Canada.\nMeanwhile, in London in 1997, journalism professor Milverton Wallace began holding an annual conference called NetMedia that offered sessions on the Internet and classes in computer-assisted reporting led by NICAR and Danish journalists. \nThe classes covered the basic uses of the Internet, spreadsheets, and database managers, and they were well-attended by journalists from the UK, other European countries, and Africa.\n \nIn Denmark, journalists Nils Mulvad and Flemming Svith, who had gone to a NICAR boot camp in Missouri in 1996, organised seminars with NICAR in 1997 and 1998 in Denmark. \nThey also wrote a Danish handbook on computer-assisted reporting, created the Danish International Center for Analytical Reporting (DICAR) in 1998 with Tommy Kaas as president. This led to them also co-organising the first Global Investigative Journalism Conference with IRE in 2001.\nCAR also became a staple of conferences in Sweden, Norway, Finland, and the Netherlands, with Helena Bengtsson from Sweden and John Bones from Norway. \nIn Brazil, the investigative journalism association, Abraji formed in 2002 with training in data journalism as part of its core mission. Two key leaders in data journalism training by Abraji in Brazil were Jose Roberto de Toledo and Marcelo Soares.\nData journalism comes of age\nThe early years of the 21st century also saw the Global Investigative Journalism Network begin to play a crucial part in the movement, starting with its first conference in 2001 in Copenhagen that offered a strong computer-assisted reporting track and hands-on training in conjunction with sessions on traditional investigative reporting.\nThrough the global investigative conferences, the use of data quickly spread across Eastern Europe. In Eastern Europe, Drew Sullivan, one of the original NICAR trainers and data administrators, formed the Organized Crime and Corruption Reporting Project, which has become a leader in data journalism.\nBy 2009, the increasing number of computer programmers and coders in journalism resulted in creation of Hacks/Hackers.\nHe and Romanian journalist Paul Radu were strong proponents and organisers of data training sessions and projects. Seminars also were given initially in China through the University of Missouri and in India through the World Press Institute, led by John Ullmann, who had been IRE’s first full-time executive director. \nUllmann also oversaw training in Latin America, recruiting me and other NICAR trainers to assist him. \nDuring the same period Doig, a pioneer in CAR and later the Knight Chair in Computer-Assisted Reporting at Arizona State University, travelled internationally to teach CAR, as did additional NICAR training directors — Sarah Cohen, Andy Lehren, Jo Craven McGinty, Tom McGinty, Ron Nixon, Neil Reisner, and Sarah Cohen -- all practising journalists who went onto work at The New York Times, The Wall Street Journal, The Washington Post, and the Miami Herald.\nVisualisation of data increases\nVisualisation of data in charts and maps had been on the rise for some time, inspired by a map by Doig in 1992 for the Miami Herald. Showing the deep value of data visualisation for analysis, Doig created a map of hurricane wind speeds and building damage in the Miami area after Hurricane Andrew. \nThe map revealed a pattern of severe property damage where wind speeds had been low. Following up on that revelation, reporters found that shoddy construction and sloppy building inspections had led to the damage.\nIn 2005, the visualisation of data for news stories got another boost when U.S. programmer Adrian Holovaty created a Google mash-up of Chicago crime data. The project spurred more interest in journalism among computer programmers and in mapping. \nHolovaty and his team of coders then created the now-defunct Every Block in 2007, which used more local data for online maps in the U.S., but the project later ran into criticism for not checking the accuracy of government data more thoroughly.\nIn 2007, the open data movement in the U.S. began in earnest, spawning other such efforts worldwide. The movement increased accessibility to government data internationally, although the need remained to have freedom of information laws to get data not released by the governments.\nThe use of data by journalists has now become so prevalent it is easier to keep track of the progress.\nBy 2009, the increasing number of computer programmers and coders in journalism resulted in creation of Hacks/Hackers, which would encourage more sharing between journalists and coders and ease some of the culture clash between the two groups.\nAron Pilhofer, then of The New York Times and now at Temple University, and Rich Gordon from Northwestern University’s Medill School of Journalism, had pushed for creation of “a network of people interested in Web/digital application development and technology innovation supporting the mission and goals of journalism.” \nAt the same time in Silicon Valley, Burt Herman brought journalists and technologists together. The three then joined to create “Hacks/Hackers.” The result has been an increasing technological sophistication within newsrooms that has increased the ability to scrape data from Web sites and make it more manageable, visual, and interactive.\nAnother outcome of the journalist-programmer mashup was the new respect among coders for knowing how flawed databases are, and for ensuring the integrity of the data.\nAs was well-said by Marcos Vanetta, a Mozilla OpenNews fellow who worked at The Texas Tribune: “Bugs are not optional… In software, we are used to making mistakes and correcting them later. We can always fix that later and in the worst case, we have a backup. In news, you can’t make mistakes -- there is a reputation to take care of. The editorial team is not as used to failure as developers are.”\n \nMore breakthroughs\nThe years 2009, 2010, and 2011 also were breakthrough years for using data for journalism. In Canada in 2009, Fred Vallance-Jones and David McKie published “Computer-Assisted Reporting: A Comprehensive Primer” with a special emphasis on CAR in Canada. \nThis was also the year that journalist Simon Rogers launched The Guardian's data blog.  \nThe European Journalism Centre began its data-driven journalism programme that has organised workshops throughout Europe. This led to the establishment of DataJournalism.com for online training courses and other resources. \nJournalist Paul Bradshaw became recognised as a pioneer in data journalism in the United Kingdom. In 2009, Wikileaks released its \"Afghan War Diaries\", composed of secret documents and then the Iraq War Diaries, requiring journalists throughout the world to deal with enormous amounts of data in text.\n \nThis was followed in 2011 by The Guardian’s impressive series using data and social media to analyse city racial riots in the United Kingdom. Journalist and author Brigitte Alfter then founded the first Dataharvest conference, which is now led by the Arena for Journalism in Europe.\nThe same year work began in London on the first Data Journalism Handbook (now in a second edition and available in several languages) it was written by a consortium of contributors from around the world.\nAlso in the United Kingdom, the Centre for Investigative Reporting, led by Gavin MacFadyen, which teamed up in its early days with IRE to offer classes in data journalism during its summer school, ran a strong programme on its own with the assistance of CAR veteran trainer David Donald.\nData journalism in the global south\nMeanwhile, at Wits University in South Africa, Anton Harber and Margaret Renn substantially increased the data sessions at the annual Power Reporting Conference, now the African Investigative Journalism Conference. \nCode For Africa founder Justin Arenstein and his team also paved the way for data journalists on the continent. In 2012, he launched Africa's largest data journalism and civic tech lab covering stories involving, environment and climate change, women, gender and health/science. \nIn Asia, journalists in countries including India, Malaysia, the Philippines, and South Korea began using digital tools, especially those for visualisation, and data stories for high impact stories and exchanging techniques and story ideas at GIJN’s biannual Asia conferences.\n \nJournalists also began incorporating social media into their investigations more often. One striking story, using social network analysis, was done by journalists in South Korea, who uncovered an attempt by intelligence officers to undermine elections through social media propaganda. Inspiring data-led interactive pieces also came out of publications like South China Morning Post. \nIn the Middle East, Egyptian data journalist Amr Eleraqi set up the Infotimes in 2012 followed by the Arab Data Journalists' Network five years later. He began teaching the first Arabic-led data journalism training programme of its kind in the region. Meanwhile, IJNET and Arab Reporters for Investigative Journalism (ARIJ) have continued to engage in offering training opportunities to Arab journalists in recent years.    \nIn Latin America, Giannina Segnini, now at Columbia University, led a team of journalists and computer engineers at La Nación in Costa Rica to produce stories by gathering, analysing, and visualising public databases.\nMeanwhile in Brazil, Natalia Mazotte from Open Knowledge Brasil launched Escola de Dados (School of Data Brazil chapter), in 2012 to train journalists with their data literacy programme. By 2015, Abraji had created online courses in data journalism.  A year later, Brazil's Coda Festival (Coda.Br) launched and grew to become the largest data journalism conference in Latin America. \nAcross the global south, data journalist Eva Constantaras began to develop training curricula for investigative and data journalism in high-risk environments with limited data access on behalf of Internews. Journalists have benefited from this data journalism training in a range of countries, including Afghanistan, India, Kenya, Kyrgyzstan and Myanmar.\nBy 2020, the COVID-19 pandemic revealed the breadth and depth of the skills journalists had accumulated.\n \nA revolution in journalism\nThe use of data by journalists and in the digital tools journalists use has vastly expanded since 2015. Journalists have probed deeper into the analysis of unstructured data -- text, video, and sound -- and woven those media into compelling investigative stories. \nThey have more routinely managed gigabytes of data for stories and organised massive data leaks with agility and become more sophisticated in visualising data through maps, social network analysis or change over time in both newsgathering and presentation. \nThey have conducted both traditional and innovative surveys to collect data to uncover social injustice. And the education and training -- and the syllabi and curricula at universities -- have become more focused and rigorous, thus producing new generations of data-savvy journalists. \nThe result has been an ever-growing stream of data-driven stories by small and large newsrooms -- often in collaborations -- that provide not only context and depth to stories, but also real facts, tips, surprises and epiphanies for journalists and their audiences. \nBy 2020, the COVID-19 pandemic revealed the breadth and depth of the skills journalists had accumulated and throughout the world journalists collected, analysed, and visualised pandemic data on a daily basis, often far exceeding what public health officials offered and, in fact, exposing the shortcomings of the data on which policy and practice were being decided.\nThe use of data by journalists has now become so prevalent it is easier to keep track of the progress and new directions by major categories. Among them:\nThe collaborations of journalists, sometimes with universities, who use huge datasets, including leaks of data. The collaboration has become nearly a standard practice and the high-profile International Consortium of Investigative Journalists (ICIJ); the Big Local News Project in the U.S. or Connectas in Latin America are just a few examples of ongoing collaborations.\nThe achievements allowed by free software that breaks the income barriers to entry into the field. The software includes a variety of tools to scrape, analyse and/or visualise data and include Google tools, Tableau, Datawrapper and many others.\nThe exploration of using Artificial Intelligence or Machine Learning to discern patterns and outliers for further reporting such as Reuters’ project called Lynx Insights, which uses an automation tool designed to help reporters accelerate the production of their existing stories or spot new ones.\nThe melding and analysis of satellite imagery, open-source video and photographs, social media, crowdsourcing and data for what are sometimes called visual or forensic investigations that are done by groups like Bellingcat.\nSurveys through emails or mobile phones, such as the \"Forced Out” project that a mobile phone survey to create a database from interviewing thousands of displaced people across South Sudan.\nThese advances, however, are not replacing but augmenting the original uses of computers and data for journalism that began by applying social science methods and statistical and data analysis to government and business corruption, health and environmental stories, and societal issues.  \nThe use of data has broadened over the years from counting instances of incidents and accidents in spreadsheets to using database managers to match apparently unrelated datasets to mapping data geographically and in social networks, to web scraping, to more efficient data cleaning, to better surveys, crowdsourcing and audience interaction, and to text mining with algorithms. \nBut all of the work is still in the service of finding patterns, trends and outliers that lead to new knowledge and better news stories in the public interest. Over the decades, there also has been much discussion on what to call the use of data for high-quality journalism and various branding efforts to label it. \nBut whether it is called “precision journalism,” “computer-assisted reporting,” “data journalism,” ‘data-driven journalism,” or “computational journalism,” the good news is that it is not only here to stay, but will continue to become more critical to revealing truths, holding the powerful accountable, and protecting those who otherwise would be exploited.\nFurther reading\n\"New Precision Journalism,\" by Philip Meyer\n\"Data for Journalists: A Practical Guide for Computer-Assisted Reporting\" by Brant Houston\n\"Data Journalism Handbook 2.0\"\n\"Data Literacy,\" by David Herzog\n\"Teaching Data and Computational Journalism\" by Charles Berret and Cheryl Phillips\nProfessor Brant Houston holds is the Knight Foundation Chair in Investigative and Enterprise Reporting at the University of Illinois. Houston teaches investigative and advanced reporting in the Department of Journalism, where he teaches investigative and data journalism. He also is editor of the online newsroom at Illinois, CU-CitizenAccess.org , which also serves as a lab for digital innovation and data journalism.","guid":"https://datajournalism.com/read/longreads/the-history-of-data-journalism","isoDate":"2021-12-13T05:30:00.000Z","blogTitle":"DataJournalism.com"}},"__N_SSG":true},"page":"/[...slug]","query":{"slug":["the-history-of-data-journalism"]},"buildId":"sFP8FhENNxqFJqEgxMEWp","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>